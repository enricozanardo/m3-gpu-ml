{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 14:22:33.482188: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 14:22:34.541983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-15 14:22:34.630582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.631538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-15 14:22:34.631593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.632522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:41:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-15 14:22:34.632543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-15 14:22:34.634893: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-15 14:22:34.634925: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-15 14:22:34.635685: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-15 14:22:34.635863: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-15 14:22:34.636554: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-15 14:22:34.637137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-15 14:22:34.637231: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-15 14:22:34.637299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.638239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.639068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.640002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.640833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-10-15 14:22:34.641171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:34.643108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# importazione librerie necessarie\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "from tensorflow.keras import utils as ku\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import mixed_precision\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONTANO NEI DIMENTICATI SPAZI NON SEGNATI NELLE CARTE GEOGRAFICHE DELL ESTREMO LIMITE DELLA SPIRALE OVEST DELLA GALASSIA C È UN PICCOLO E INSIGNIFICANTE SOLE GIALLO A ORBITARE INTORNO A ESSO ALLA DISTANZA DI CENTOQUARANTANOVE MILIONI DI CHILOMETRI C È UN PICCOLO TRASCURABILISSIMO PIANETA AZZURRO VERDE LE CUI FORME DI VITA DISCENDENTI DALLE SCIMMIE SONO COSÌ INCREDIBILMENTE PRIMITIVE CHE CREDONO ANCORA CHE GLI OROLOGI DA POLSO DIGITALI SIANO UN OTTIMA INVENZIONE QUESTO PIANETA HA O MEGLIO AVEVA U\n"
     ]
    }
   ],
   "source": [
    "filters = '…,.!?§«»ª™#$%&()*‘’`\"”\"\\'+-–/:;<=>@[\\\\]^_{|}~\\t\\n\\x0c'\n",
    "\n",
    "text = open(\"data/guida_galattica_per_gli_autostoppisti.txt\", encoding='utf-8').read()\n",
    "text2 = open(\"data/ristorante_al_termine_dell_universo.txt\", encoding='utf-8').read()\n",
    "text3 = open(\"data/la_vita_l_universo_e_tutto_quanto.txt\", encoding='utf-8').read()\n",
    "text4 = open(\"data/addio_e_grazie_per_tutto_il_pesce.txt\", encoding='utf-8').read()\n",
    "text5 = open(\"data/praticamente_innocuo.txt\", encoding='utf-8').read()\n",
    "\n",
    "text += ' ' + text2 + ' ' + text3 + ' ' + text4 + ' ' + text5\n",
    "\n",
    "text = text.upper()\n",
    "\n",
    "# rimozione dei caratteri speciali\n",
    "# n.b. non rimuoviamo le cifre quindi\n",
    "# i numeri presenti nel testo saranno\n",
    "# considerati ognuno come una \"parola\"\n",
    "# fatta di lettere nel testo\n",
    "for c in filters:\n",
    "    text = text.replace(c, ' ')\n",
    "\n",
    "text = text.replace('  ', ' ')\n",
    "\n",
    "# visualizzazione dell'inizio del\n",
    "# testo delle cinque parti della trilogia :)\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281850 numero totale di parole nei testi\n",
      "22919 parole uniche nei testi\n"
     ]
    }
   ],
   "source": [
    "text = text.split(' ')\n",
    "print(len(text), 'numero totale di parole nei testi')\n",
    "print(len(set(text)), 'parole uniche nei testi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140893 esempi\n",
      "\n",
      "['LONTANO', 'NEI', 'DIMENTICATI', 'SPAZI', 'NON', 'SEGNATI', 'NELLE', 'CARTE', 'GEOGRAFICHE', 'DELL', 'ESTREMO', 'LIMITE', 'DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO']\n",
      "['DIMENTICATI', 'SPAZI', 'NON', 'SEGNATI', 'NELLE', 'CARTE', 'GEOGRAFICHE', 'DELL', 'ESTREMO', 'LIMITE', 'DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO']\n",
      "['NON', 'SEGNATI', 'NELLE', 'CARTE', 'GEOGRAFICHE', 'DELL', 'ESTREMO', 'LIMITE', 'DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA']\n",
      "['NELLE', 'CARTE', 'GEOGRAFICHE', 'DELL', 'ESTREMO', 'LIMITE', 'DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO']\n",
      "['GEOGRAFICHE', 'DELL', 'ESTREMO', 'LIMITE', 'DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA']\n",
      "['ESTREMO', 'LIMITE', 'DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO']\n",
      "['DELLA', 'SPIRALE', 'OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN']\n",
      "['OVEST', 'DELLA', 'GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA']\n",
      "['GALASSIA', 'C', 'È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR']\n",
      "['È', 'UN', 'PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR', 'PARTE', 'DEI']\n",
      "['PICCOLO', 'E', 'INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR', 'PARTE', 'DEI', 'SUOI', 'ABITANTI']\n",
      "['INSIGNIFICANTE', 'SOLE', 'GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR', 'PARTE', 'DEI', 'SUOI', 'ABITANTI', 'ERANO', 'INFATTI']\n",
      "['GIALLO', 'A', 'ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR', 'PARTE', 'DEI', 'SUOI', 'ABITANTI', 'ERANO', 'INFATTI', 'AFFLITTI', 'DA']\n",
      "['ORBITARE', 'INTORNO', 'A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR', 'PARTE', 'DEI', 'SUOI', 'ABITANTI', 'ERANO', 'INFATTI', 'AFFLITTI', 'DA', 'UNA', 'QUASI']\n",
      "['A', 'ESSO', 'ALLA', 'DISTANZA', 'DI', 'CENTOQUARANTANOVE', 'MILIONI', 'DI', 'CHILOMETRI', 'C', 'È', 'UN', 'PICCOLO', 'TRASCURABILISSIMO', 'PIANETA', 'AZZURRO', 'VERDE', 'LE', 'CUI', 'FORME', 'DI', 'VITA', 'DISCENDENTI', 'DALLE', 'SCIMMIE', 'SONO', 'COSÌ', 'INCREDIBILMENTE', 'PRIMITIVE', 'CHE', 'CREDONO', 'ANCORA', 'CHE', 'GLI', 'OROLOGI', 'DA', 'POLSO', 'DIGITALI', 'SIANO', 'UN', 'OTTIMA', 'INVENZIONE', 'QUESTO', 'PIANETA', 'HA', 'O', 'MEGLIO', 'AVEVA', 'UN', 'FONDAMENTALE', 'PROBLEMA', 'LA', 'MAGGIOR', 'PARTE', 'DEI', 'SUOI', 'ABITANTI', 'ERANO', 'INFATTI', 'AFFLITTI', 'DA', 'UNA', 'QUASI', 'COSTANTE', 'INFELICITÀ']\n"
     ]
    }
   ],
   "source": [
    "sentence_len = 64 + 1  # 64 x_train + 1 y_train\n",
    "step = 2\n",
    "\n",
    "texts = []\n",
    "\n",
    "for i in range(0, len(text) - sentence_len, step):\n",
    "    texts.append(text[i:i + sentence_len])\n",
    "\n",
    "print(len(texts), 'esempi')\n",
    "print('')\n",
    "for i in range(15):\n",
    "    print(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_words = 10000  # le 10000 parole più frequenti nei testi\n",
    "                   # pari a poco meno del 50% dell'intero dizionario\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=max_words,\n",
    "    oov_token='___',  # token per le circa 13000 parole meno\n",
    "                      # frequenti nei testi\n",
    ")\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# avendo utilizzato l'out-of-vocabulary token, non c'è\n",
    "# necessità di effettuare un padding delle sequenze\n",
    "# alternativamente si dovrebbe eseguire:\n",
    "#\n",
    "# input_sequences = pad_sequences(\n",
    "#     input_sequences,\n",
    "#     padding=\"post\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "examples = [x[:-1] for x in input_sequences]\n",
    "labels = [x[-1] for x in input_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = ku.to_categorical(labels, num_classes=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples : (140893, 64)\n",
      "Labels   : (140893, 10000)\n"
     ]
    }
   ],
   "source": [
    "examples = np.asarray(examples)\n",
    "labels  = np.asarray(labels)\n",
    "\n",
    "print('Examples :', examples.shape)\n",
    "print('Labels   :', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 14:22:42.983794: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-15 14:22:43.151237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:43.152277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-15 14:22:43.152329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:43.153105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:41:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-15 14:22:43.153151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:43.154023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:43.155028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:43.156055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:43.156824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-10-15 14:22:43.156867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-15 14:22:44.133925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-15 14:22:44.133961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2021-10-15 14:22:44.133966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N \n",
      "2021-10-15 14:22:44.133970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N \n",
      "2021-10-15 14:22:44.134184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:44.135128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:44.135936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:44.136832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:44.137632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:44.138500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22310 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2021-10-15 14:22:44.138923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-15 14:22:44.139713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 19193 MB memory) -> physical GPU (device: 1, name: GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 64, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64, 2048)          17833984  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64, 1024)          12587008  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64, 512)           3147776   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64, 1024)          6295552   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 2048)              25174016  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10000)             20490000  \n",
      "=================================================================\n",
      "Total params: 86,808,336\n",
      "Trainable params: 86,808,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 128, input_length=len(examples[0])))\n",
    "    model.add(LSTM(2048, return_sequences=True))\n",
    "    model.add(LSTM(1024, return_sequences=True))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(LSTM(1024, return_sequences=True))\n",
    "    model.add(LSTM(2048))\n",
    "    model.add(Dense(max_words, activation='softmax', dtype='float32'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.003, epsilon=1e-9), metrics='accuracy')\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 14:23:03.022865: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-15 14:23:03.040108: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2994670000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 14:23:07.000703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-15 14:23:07.573193: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2021-10-15 14:23:07.876856: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-15 14:23:08.392438: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-15 14:23:08.392507: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/276 - 72s - loss: 7.0672 - accuracy: 0.0444\n",
      "Epoch 2/1000\n",
      "276/276 - 68s - loss: 7.0006 - accuracy: 0.0436\n",
      "Epoch 3/1000\n",
      "276/276 - 69s - loss: 6.9259 - accuracy: 0.0444\n",
      "Epoch 4/1000\n",
      "276/276 - 69s - loss: 6.9208 - accuracy: 0.0446\n",
      "Epoch 5/1000\n",
      "276/276 - 69s - loss: 6.9164 - accuracy: 0.0439\n",
      "Epoch 6/1000\n",
      "276/276 - 69s - loss: 6.9136 - accuracy: 0.0447\n",
      "Epoch 7/1000\n",
      "276/276 - 69s - loss: 6.9129 - accuracy: 0.0441\n",
      "Epoch 8/1000\n",
      "276/276 - 69s - loss: 6.9118 - accuracy: 0.0436\n",
      "Epoch 9/1000\n",
      "276/276 - 69s - loss: 6.9138 - accuracy: 0.0448\n",
      "Epoch 10/1000\n",
      "276/276 - 69s - loss: 6.9110 - accuracy: 0.0446\n",
      "Epoch 11/1000\n",
      "276/276 - 69s - loss: 6.9108 - accuracy: 0.0450\n",
      "Epoch 12/1000\n",
      "276/276 - 69s - loss: 6.9130 - accuracy: 0.0441\n",
      "Epoch 13/1000\n",
      "276/276 - 69s - loss: 6.9116 - accuracy: 0.0448\n",
      "Epoch 14/1000\n",
      "276/276 - 69s - loss: 6.9099 - accuracy: 0.0449\n",
      "Epoch 15/1000\n",
      "276/276 - 68s - loss: 6.9108 - accuracy: 0.0439\n",
      "Epoch 16/1000\n",
      "276/276 - 68s - loss: 6.9102 - accuracy: 0.0449\n",
      "Epoch 17/1000\n",
      "276/276 - 68s - loss: 6.9086 - accuracy: 0.0441\n",
      "Epoch 18/1000\n",
      "276/276 - 68s - loss: 6.9099 - accuracy: 0.0444\n",
      "Epoch 19/1000\n",
      "276/276 - 68s - loss: 6.9110 - accuracy: 0.0441\n",
      "Epoch 20/1000\n",
      "276/276 - 68s - loss: 6.9090 - accuracy: 0.0440\n",
      "Epoch 21/1000\n",
      "276/276 - 68s - loss: 6.9097 - accuracy: 0.0447\n",
      "Epoch 22/1000\n",
      "276/276 - 68s - loss: 6.9073 - accuracy: 0.0454\n",
      "Epoch 23/1000\n",
      "276/276 - 68s - loss: 6.9091 - accuracy: 0.0448\n",
      "Epoch 24/1000\n",
      "276/276 - 68s - loss: 6.9086 - accuracy: 0.0442\n",
      "Epoch 25/1000\n",
      "276/276 - 68s - loss: 6.9103 - accuracy: 0.0434\n",
      "Epoch 26/1000\n",
      "276/276 - 68s - loss: 6.9077 - accuracy: 0.0445\n",
      "Epoch 27/1000\n",
      "276/276 - 68s - loss: 6.9096 - accuracy: 0.0448\n",
      "Epoch 28/1000\n",
      "276/276 - 68s - loss: 6.9094 - accuracy: 0.0441\n",
      "Epoch 29/1000\n",
      "276/276 - 68s - loss: 6.9108 - accuracy: 0.0449\n",
      "Epoch 30/1000\n",
      "276/276 - 68s - loss: 6.9087 - accuracy: 0.0440\n",
      "Epoch 31/1000\n",
      "276/276 - 68s - loss: 6.9077 - accuracy: 0.0450\n",
      "Epoch 32/1000\n",
      "276/276 - 68s - loss: 6.9090 - accuracy: 0.0440\n",
      "Epoch 33/1000\n",
      "276/276 - 68s - loss: 6.9095 - accuracy: 0.0446\n",
      "Epoch 34/1000\n",
      "276/276 - 68s - loss: 6.9092 - accuracy: 0.0448\n",
      "Epoch 35/1000\n",
      "276/276 - 68s - loss: 6.9089 - accuracy: 0.0448\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.002250000019557774.\n",
      "Epoch 36/1000\n",
      "276/276 - 68s - loss: 6.8531 - accuracy: 0.0437\n",
      "Epoch 37/1000\n",
      "276/276 - 68s - loss: 6.8474 - accuracy: 0.0444\n",
      "Epoch 38/1000\n",
      "276/276 - 68s - loss: 6.8483 - accuracy: 0.0436\n",
      "Epoch 39/1000\n",
      "276/276 - 68s - loss: 6.8496 - accuracy: 0.0449\n",
      "Epoch 40/1000\n",
      "276/276 - 68s - loss: 6.8473 - accuracy: 0.0456\n",
      "Epoch 41/1000\n",
      "276/276 - 68s - loss: 6.8482 - accuracy: 0.0446\n",
      "Epoch 42/1000\n",
      "276/276 - 68s - loss: 6.8493 - accuracy: 0.0449\n",
      "Epoch 43/1000\n",
      "276/276 - 68s - loss: 6.8482 - accuracy: 0.0447\n",
      "Epoch 44/1000\n",
      "276/276 - 68s - loss: 6.8500 - accuracy: 0.0448\n",
      "Epoch 45/1000\n",
      "276/276 - 68s - loss: 6.8479 - accuracy: 0.0440\n",
      "Epoch 46/1000\n",
      "276/276 - 68s - loss: 6.8503 - accuracy: 0.0447\n",
      "Epoch 47/1000\n",
      "276/276 - 68s - loss: 6.8484 - accuracy: 0.0451\n",
      "Epoch 48/1000\n",
      "276/276 - 68s - loss: 6.8502 - accuracy: 0.0442\n",
      "Epoch 49/1000\n",
      "276/276 - 68s - loss: 6.8502 - accuracy: 0.0445\n",
      "Epoch 50/1000\n",
      "276/276 - 68s - loss: 6.8511 - accuracy: 0.0449\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0016874999273568392.\n",
      "Epoch 51/1000\n",
      "276/276 - 68s - loss: 6.8080 - accuracy: 0.0448\n",
      "Epoch 52/1000\n",
      "276/276 - 68s - loss: 6.8029 - accuracy: 0.0448\n",
      "Epoch 53/1000\n",
      "276/276 - 68s - loss: 6.8037 - accuracy: 0.0440\n",
      "Epoch 54/1000\n",
      "276/276 - 68s - loss: 6.8037 - accuracy: 0.0445\n",
      "Epoch 55/1000\n",
      "276/276 - 68s - loss: 6.8032 - accuracy: 0.0455\n",
      "Epoch 56/1000\n",
      "276/276 - 68s - loss: 6.8038 - accuracy: 0.0443\n",
      "Epoch 57/1000\n",
      "276/276 - 68s - loss: 6.8041 - accuracy: 0.0446\n",
      "Epoch 58/1000\n",
      "276/276 - 68s - loss: 6.8040 - accuracy: 0.0451\n",
      "Epoch 59/1000\n",
      "276/276 - 68s - loss: 6.8044 - accuracy: 0.0456\n",
      "Epoch 60/1000\n",
      "276/276 - 68s - loss: 6.8041 - accuracy: 0.0455\n",
      "Epoch 61/1000\n",
      "276/276 - 68s - loss: 6.8044 - accuracy: 0.0453\n",
      "Epoch 62/1000\n",
      "276/276 - 68s - loss: 6.8052 - accuracy: 0.0447\n",
      "Epoch 63/1000\n",
      "276/276 - 68s - loss: 6.8028 - accuracy: 0.0457\n",
      "Epoch 64/1000\n",
      "276/276 - 68s - loss: 6.8067 - accuracy: 0.0463\n",
      "Epoch 65/1000\n",
      "276/276 - 68s - loss: 6.8047 - accuracy: 0.0441\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0012656249455176294.\n",
      "Epoch 66/1000\n",
      "276/276 - 68s - loss: 6.8440 - accuracy: 0.0449\n",
      "Epoch 67/1000\n",
      "276/276 - 68s - loss: 6.9709 - accuracy: 0.0451\n",
      "Epoch 68/1000\n",
      "276/276 - 68s - loss: 6.9614 - accuracy: 0.0445\n",
      "Epoch 69/1000\n",
      "276/276 - 68s - loss: 6.8902 - accuracy: 0.0450\n",
      "Epoch 70/1000\n",
      "276/276 - 68s - loss: 6.8415 - accuracy: 0.0446\n",
      "Epoch 71/1000\n",
      "276/276 - 68s - loss: 6.7977 - accuracy: 0.0454\n",
      "Epoch 72/1000\n",
      "276/276 - 68s - loss: 6.7834 - accuracy: 0.0445\n",
      "Epoch 73/1000\n",
      "276/276 - 68s - loss: 6.7837 - accuracy: 0.0455\n",
      "Epoch 74/1000\n",
      "276/276 - 68s - loss: 6.8841 - accuracy: 0.0448\n",
      "Epoch 75/1000\n",
      "276/276 - 68s - loss: 6.8680 - accuracy: 0.0447\n",
      "Epoch 76/1000\n",
      "276/276 - 68s - loss: 6.7998 - accuracy: 0.0446\n",
      "Epoch 77/1000\n",
      "276/276 - 68s - loss: 6.7833 - accuracy: 0.0456\n",
      "Epoch 78/1000\n",
      "276/276 - 68s - loss: 6.7861 - accuracy: 0.0444\n",
      "Epoch 79/1000\n",
      "276/276 - 68s - loss: 6.7710 - accuracy: 0.0452\n",
      "Epoch 80/1000\n",
      "276/276 - 68s - loss: 6.7694 - accuracy: 0.0457\n",
      "Epoch 81/1000\n",
      "276/276 - 68s - loss: 6.7780 - accuracy: 0.0447\n",
      "Epoch 82/1000\n",
      "276/276 - 68s - loss: 6.7869 - accuracy: 0.0448\n",
      "Epoch 83/1000\n",
      "276/276 - 68s - loss: 6.7660 - accuracy: 0.0452\n",
      "Epoch 84/1000\n",
      "276/276 - 68s - loss: 6.7589 - accuracy: 0.0450\n",
      "Epoch 85/1000\n",
      "276/276 - 68s - loss: 6.7547 - accuracy: 0.0449\n",
      "Epoch 86/1000\n",
      "276/276 - 68s - loss: 6.7717 - accuracy: 0.0450\n",
      "Epoch 87/1000\n",
      "276/276 - 68s - loss: 6.7700 - accuracy: 0.0454\n",
      "Epoch 88/1000\n",
      "276/276 - 68s - loss: 6.7546 - accuracy: 0.0455\n",
      "Epoch 89/1000\n",
      "276/276 - 68s - loss: 6.7475 - accuracy: 0.0452\n",
      "Epoch 90/1000\n",
      "276/276 - 68s - loss: 6.7298 - accuracy: 0.0448\n",
      "Epoch 91/1000\n",
      "276/276 - 68s - loss: 6.7235 - accuracy: 0.0455\n",
      "Epoch 92/1000\n",
      "276/276 - 68s - loss: 6.7189 - accuracy: 0.0457\n",
      "Epoch 93/1000\n",
      "276/276 - 68s - loss: 6.7157 - accuracy: 0.0454\n",
      "Epoch 94/1000\n",
      "276/276 - 68s - loss: 6.7061 - accuracy: 0.0461\n",
      "Epoch 95/1000\n",
      "276/276 - 68s - loss: 6.7056 - accuracy: 0.0453\n",
      "Epoch 96/1000\n",
      "276/276 - 68s - loss: 6.7030 - accuracy: 0.0456\n",
      "Epoch 97/1000\n",
      "276/276 - 68s - loss: 6.6883 - accuracy: 0.0455\n",
      "Epoch 98/1000\n",
      "276/276 - 68s - loss: 6.6727 - accuracy: 0.0451\n",
      "Epoch 99/1000\n",
      "276/276 - 68s - loss: 6.6611 - accuracy: 0.0455\n",
      "Epoch 100/1000\n",
      "276/276 - 68s - loss: 6.6517 - accuracy: 0.0460\n",
      "Epoch 101/1000\n",
      "276/276 - 68s - loss: 6.6321 - accuracy: 0.0461\n",
      "Epoch 102/1000\n",
      "276/276 - 68s - loss: 6.6143 - accuracy: 0.0458\n",
      "Epoch 103/1000\n",
      "276/276 - 68s - loss: 6.6051 - accuracy: 0.0456\n",
      "Epoch 104/1000\n",
      "276/276 - 68s - loss: 6.5858 - accuracy: 0.0463\n",
      "Epoch 105/1000\n",
      "276/276 - 68s - loss: 6.5674 - accuracy: 0.0468\n",
      "Epoch 106/1000\n",
      "276/276 - 68s - loss: 6.5528 - accuracy: 0.0463\n",
      "Epoch 107/1000\n",
      "276/276 - 68s - loss: 6.5490 - accuracy: 0.0468\n",
      "Epoch 108/1000\n",
      "276/276 - 68s - loss: 6.5288 - accuracy: 0.0468\n",
      "Epoch 109/1000\n",
      "276/276 - 68s - loss: 6.5126 - accuracy: 0.0481\n",
      "Epoch 110/1000\n",
      "276/276 - 68s - loss: 6.4926 - accuracy: 0.0475\n",
      "Epoch 111/1000\n",
      "276/276 - 68s - loss: 6.4816 - accuracy: 0.0470\n",
      "Epoch 112/1000\n",
      "276/276 - 68s - loss: 6.4660 - accuracy: 0.0478\n",
      "Epoch 113/1000\n",
      "276/276 - 68s - loss: 6.4550 - accuracy: 0.0473\n",
      "Epoch 114/1000\n",
      "276/276 - 68s - loss: 6.4450 - accuracy: 0.0473\n",
      "Epoch 115/1000\n",
      "276/276 - 68s - loss: 6.4277 - accuracy: 0.0475\n",
      "Epoch 116/1000\n",
      "276/276 - 68s - loss: 6.4124 - accuracy: 0.0477\n",
      "Epoch 117/1000\n",
      "276/276 - 68s - loss: 6.3995 - accuracy: 0.0482\n",
      "Epoch 118/1000\n",
      "276/276 - 68s - loss: 6.3848 - accuracy: 0.0480\n",
      "Epoch 119/1000\n",
      "276/276 - 68s - loss: 6.3735 - accuracy: 0.0482\n",
      "Epoch 120/1000\n",
      "276/276 - 68s - loss: 6.3610 - accuracy: 0.0480\n",
      "Epoch 121/1000\n",
      "276/276 - 68s - loss: 6.3487 - accuracy: 0.0482\n",
      "Epoch 122/1000\n",
      "276/276 - 68s - loss: 6.3355 - accuracy: 0.0483\n",
      "Epoch 123/1000\n",
      "276/276 - 68s - loss: 6.3214 - accuracy: 0.0486\n",
      "Epoch 124/1000\n",
      "276/276 - 68s - loss: 6.3095 - accuracy: 0.0488\n",
      "Epoch 125/1000\n",
      "276/276 - 68s - loss: 6.2948 - accuracy: 0.0487\n",
      "Epoch 126/1000\n",
      "276/276 - 68s - loss: 6.2845 - accuracy: 0.0485\n",
      "Epoch 127/1000\n",
      "276/276 - 68s - loss: 6.2715 - accuracy: 0.0494\n",
      "Epoch 128/1000\n",
      "276/276 - 68s - loss: 6.2580 - accuracy: 0.0493\n",
      "Epoch 129/1000\n",
      "276/276 - 68s - loss: 6.2465 - accuracy: 0.0489\n",
      "Epoch 130/1000\n",
      "276/276 - 68s - loss: 6.2354 - accuracy: 0.0489\n",
      "Epoch 131/1000\n",
      "276/276 - 68s - loss: 6.2265 - accuracy: 0.0497\n",
      "Epoch 132/1000\n",
      "276/276 - 68s - loss: 6.2144 - accuracy: 0.0495\n",
      "Epoch 133/1000\n",
      "276/276 - 68s - loss: 6.2020 - accuracy: 0.0493\n",
      "Epoch 134/1000\n",
      "276/276 - 68s - loss: 6.1867 - accuracy: 0.0496\n",
      "Epoch 135/1000\n",
      "276/276 - 68s - loss: 6.1766 - accuracy: 0.0490\n",
      "Epoch 136/1000\n",
      "276/276 - 68s - loss: 6.1642 - accuracy: 0.0494\n",
      "Epoch 137/1000\n",
      "276/276 - 68s - loss: 6.1561 - accuracy: 0.0495\n",
      "Epoch 138/1000\n",
      "276/276 - 68s - loss: 6.1446 - accuracy: 0.0498\n",
      "Epoch 139/1000\n",
      "276/276 - 68s - loss: 6.1322 - accuracy: 0.0495\n",
      "Epoch 140/1000\n",
      "276/276 - 68s - loss: 6.1221 - accuracy: 0.0495\n",
      "Epoch 141/1000\n",
      "276/276 - 68s - loss: 6.1115 - accuracy: 0.0502\n",
      "Epoch 142/1000\n",
      "276/276 - 68s - loss: 6.1039 - accuracy: 0.0496\n",
      "Epoch 143/1000\n",
      "276/276 - 68s - loss: 6.0935 - accuracy: 0.0502\n",
      "Epoch 144/1000\n",
      "276/276 - 68s - loss: 6.0828 - accuracy: 0.0504\n",
      "Epoch 145/1000\n",
      "276/276 - 68s - loss: 6.0734 - accuracy: 0.0503\n",
      "Epoch 146/1000\n",
      "276/276 - 68s - loss: 6.0635 - accuracy: 0.0505\n",
      "Epoch 147/1000\n",
      "276/276 - 68s - loss: 6.0529 - accuracy: 0.0506\n",
      "Epoch 148/1000\n",
      "276/276 - 67s - loss: 6.0418 - accuracy: 0.0506\n",
      "Epoch 149/1000\n",
      "276/276 - 67s - loss: 6.0347 - accuracy: 0.0509\n",
      "Epoch 150/1000\n",
      "276/276 - 67s - loss: 6.0246 - accuracy: 0.0507\n",
      "Epoch 151/1000\n",
      "276/276 - 68s - loss: 6.0139 - accuracy: 0.0514\n",
      "Epoch 152/1000\n",
      "276/276 - 68s - loss: 6.0048 - accuracy: 0.0509\n",
      "Epoch 153/1000\n",
      "276/276 - 68s - loss: 5.9940 - accuracy: 0.0514\n",
      "Epoch 154/1000\n",
      "276/276 - 68s - loss: 5.9836 - accuracy: 0.0512\n",
      "Epoch 155/1000\n",
      "276/276 - 68s - loss: 5.9758 - accuracy: 0.0513\n",
      "Epoch 156/1000\n",
      "276/276 - 68s - loss: 5.9653 - accuracy: 0.0510\n",
      "Epoch 157/1000\n",
      "276/276 - 68s - loss: 5.9527 - accuracy: 0.0519\n",
      "Epoch 158/1000\n",
      "276/276 - 68s - loss: 5.9453 - accuracy: 0.0515\n",
      "Epoch 159/1000\n",
      "276/276 - 69s - loss: 5.9328 - accuracy: 0.0520\n",
      "Epoch 160/1000\n",
      "276/276 - 69s - loss: 5.9262 - accuracy: 0.0518\n",
      "Epoch 161/1000\n",
      "276/276 - 69s - loss: 5.9173 - accuracy: 0.0519\n",
      "Epoch 162/1000\n",
      "276/276 - 69s - loss: 5.9042 - accuracy: 0.0527\n",
      "Epoch 163/1000\n",
      "276/276 - 69s - loss: 5.8939 - accuracy: 0.0520\n",
      "Epoch 164/1000\n",
      "276/276 - 70s - loss: 5.8838 - accuracy: 0.0527\n",
      "Epoch 165/1000\n",
      "276/276 - 70s - loss: 5.8743 - accuracy: 0.0527\n",
      "Epoch 166/1000\n",
      "276/276 - 70s - loss: 5.8665 - accuracy: 0.0522\n",
      "Epoch 167/1000\n",
      "276/276 - 70s - loss: 5.8567 - accuracy: 0.0531\n",
      "Epoch 168/1000\n",
      "276/276 - 70s - loss: 5.8485 - accuracy: 0.0530\n",
      "Epoch 169/1000\n",
      "276/276 - 70s - loss: 5.8363 - accuracy: 0.0527\n",
      "Epoch 170/1000\n",
      "276/276 - 70s - loss: 5.8251 - accuracy: 0.0534\n",
      "Epoch 171/1000\n",
      "276/276 - 70s - loss: 5.8164 - accuracy: 0.0536\n",
      "Epoch 172/1000\n",
      "276/276 - 70s - loss: 5.8067 - accuracy: 0.0537\n",
      "Epoch 173/1000\n",
      "276/276 - 70s - loss: 5.7973 - accuracy: 0.0539\n",
      "Epoch 174/1000\n",
      "276/276 - 70s - loss: 5.7855 - accuracy: 0.0536\n",
      "Epoch 175/1000\n",
      "276/276 - 70s - loss: 5.7800 - accuracy: 0.0538\n",
      "Epoch 176/1000\n",
      "276/276 - 70s - loss: 5.7739 - accuracy: 0.0538\n",
      "Epoch 177/1000\n",
      "276/276 - 70s - loss: 5.7623 - accuracy: 0.0539\n",
      "Epoch 178/1000\n",
      "276/276 - 70s - loss: 5.7558 - accuracy: 0.0540\n",
      "Epoch 179/1000\n",
      "276/276 - 70s - loss: 5.7479 - accuracy: 0.0540\n",
      "Epoch 180/1000\n",
      "276/276 - 70s - loss: 5.7377 - accuracy: 0.0544\n",
      "Epoch 181/1000\n",
      "276/276 - 70s - loss: 5.7257 - accuracy: 0.0545\n",
      "Epoch 182/1000\n",
      "276/276 - 70s - loss: 5.7152 - accuracy: 0.0554\n",
      "Epoch 183/1000\n",
      "276/276 - 70s - loss: 5.7073 - accuracy: 0.0553\n",
      "Epoch 184/1000\n",
      "276/276 - 70s - loss: 5.6963 - accuracy: 0.0552\n",
      "Epoch 185/1000\n",
      "276/276 - 70s - loss: 5.6850 - accuracy: 0.0551\n",
      "Epoch 186/1000\n",
      "276/276 - 70s - loss: 5.6742 - accuracy: 0.0557\n",
      "Epoch 187/1000\n",
      "276/276 - 70s - loss: 5.6663 - accuracy: 0.0559\n",
      "Epoch 188/1000\n",
      "276/276 - 70s - loss: 5.6584 - accuracy: 0.0562\n",
      "Epoch 189/1000\n",
      "276/276 - 70s - loss: 5.6503 - accuracy: 0.0554\n",
      "Epoch 190/1000\n",
      "276/276 - 70s - loss: 5.6407 - accuracy: 0.0561\n",
      "Epoch 191/1000\n",
      "276/276 - 70s - loss: 5.6330 - accuracy: 0.0563\n",
      "Epoch 192/1000\n",
      "276/276 - 70s - loss: 5.6214 - accuracy: 0.0568\n",
      "Epoch 193/1000\n",
      "276/276 - 70s - loss: 5.6136 - accuracy: 0.0564\n",
      "Epoch 194/1000\n",
      "276/276 - 70s - loss: 5.6042 - accuracy: 0.0572\n",
      "Epoch 195/1000\n",
      "276/276 - 70s - loss: 5.5938 - accuracy: 0.0570\n",
      "Epoch 196/1000\n",
      "276/276 - 70s - loss: 5.5872 - accuracy: 0.0570\n",
      "Epoch 197/1000\n",
      "276/276 - 69s - loss: 5.5740 - accuracy: 0.0572\n",
      "Epoch 198/1000\n",
      "276/276 - 69s - loss: 5.5667 - accuracy: 0.0569\n",
      "Epoch 199/1000\n",
      "276/276 - 69s - loss: 5.5555 - accuracy: 0.0577\n",
      "Epoch 200/1000\n",
      "276/276 - 69s - loss: 5.5461 - accuracy: 0.0571\n",
      "Epoch 201/1000\n",
      "276/276 - 69s - loss: 5.5412 - accuracy: 0.0579\n",
      "Epoch 202/1000\n",
      "276/276 - 69s - loss: 5.5297 - accuracy: 0.0582\n",
      "Epoch 203/1000\n",
      "276/276 - 69s - loss: 5.5190 - accuracy: 0.0588\n",
      "Epoch 204/1000\n",
      "276/276 - 69s - loss: 5.5103 - accuracy: 0.0586\n",
      "Epoch 205/1000\n",
      "276/276 - 69s - loss: 5.5032 - accuracy: 0.0588\n",
      "Epoch 206/1000\n",
      "276/276 - 68s - loss: 5.4935 - accuracy: 0.0584\n",
      "Epoch 207/1000\n",
      "276/276 - 68s - loss: 5.4834 - accuracy: 0.0596\n",
      "Epoch 208/1000\n",
      "276/276 - 68s - loss: 5.4755 - accuracy: 0.0596\n",
      "Epoch 209/1000\n",
      "276/276 - 68s - loss: 5.4669 - accuracy: 0.0598\n",
      "Epoch 210/1000\n",
      "276/276 - 68s - loss: 5.4573 - accuracy: 0.0603\n",
      "Epoch 211/1000\n",
      "276/276 - 68s - loss: 5.4499 - accuracy: 0.0603\n",
      "Epoch 212/1000\n",
      "276/276 - 68s - loss: 5.4384 - accuracy: 0.0605\n",
      "Epoch 213/1000\n",
      "276/276 - 68s - loss: 5.4311 - accuracy: 0.0613\n",
      "Epoch 214/1000\n",
      "276/276 - 67s - loss: 5.4219 - accuracy: 0.0611\n",
      "Epoch 215/1000\n",
      "276/276 - 67s - loss: 5.4104 - accuracy: 0.0614\n",
      "Epoch 216/1000\n",
      "276/276 - 67s - loss: 5.4029 - accuracy: 0.0613\n",
      "Epoch 217/1000\n",
      "276/276 - 67s - loss: 5.3941 - accuracy: 0.0623\n",
      "Epoch 218/1000\n",
      "276/276 - 67s - loss: 5.3843 - accuracy: 0.0614\n",
      "Epoch 219/1000\n",
      "276/276 - 67s - loss: 5.3811 - accuracy: 0.0623\n",
      "Epoch 220/1000\n",
      "276/276 - 68s - loss: 5.3706 - accuracy: 0.0631\n",
      "Epoch 221/1000\n",
      "276/276 - 68s - loss: 5.3548 - accuracy: 0.0633\n",
      "Epoch 222/1000\n",
      "276/276 - 68s - loss: 5.3443 - accuracy: 0.0640\n",
      "Epoch 223/1000\n",
      "276/276 - 68s - loss: 5.3339 - accuracy: 0.0646\n",
      "Epoch 224/1000\n",
      "276/276 - 68s - loss: 5.3277 - accuracy: 0.0643\n",
      "Epoch 225/1000\n",
      "276/276 - 68s - loss: 5.3154 - accuracy: 0.0657\n",
      "Epoch 226/1000\n",
      "276/276 - 68s - loss: 5.3080 - accuracy: 0.0660\n",
      "Epoch 227/1000\n",
      "276/276 - 68s - loss: 5.2973 - accuracy: 0.0661\n",
      "Epoch 228/1000\n",
      "276/276 - 69s - loss: 5.2876 - accuracy: 0.0669\n",
      "Epoch 229/1000\n",
      "276/276 - 69s - loss: 5.2772 - accuracy: 0.0669\n",
      "Epoch 230/1000\n",
      "276/276 - 69s - loss: 5.2707 - accuracy: 0.0674\n",
      "Epoch 231/1000\n",
      "276/276 - 69s - loss: 5.2628 - accuracy: 0.0681\n",
      "Epoch 232/1000\n",
      "276/276 - 70s - loss: 5.2553 - accuracy: 0.0682\n",
      "Epoch 233/1000\n",
      "276/276 - 70s - loss: 5.2451 - accuracy: 0.0684\n",
      "Epoch 234/1000\n",
      "276/276 - 70s - loss: 5.2333 - accuracy: 0.0691\n",
      "Epoch 235/1000\n",
      "276/276 - 70s - loss: 5.2238 - accuracy: 0.0698\n",
      "Epoch 236/1000\n",
      "276/276 - 70s - loss: 5.2118 - accuracy: 0.0702\n",
      "Epoch 237/1000\n",
      "276/276 - 70s - loss: 5.2010 - accuracy: 0.0710\n",
      "Epoch 238/1000\n",
      "276/276 - 70s - loss: 5.1909 - accuracy: 0.0716\n",
      "Epoch 239/1000\n",
      "276/276 - 70s - loss: 5.1747 - accuracy: 0.0729\n",
      "Epoch 240/1000\n",
      "276/276 - 70s - loss: 5.1453 - accuracy: 0.0760\n",
      "Epoch 241/1000\n",
      "276/276 - 70s - loss: 5.1019 - accuracy: 0.0810\n",
      "Epoch 242/1000\n",
      "276/276 - 70s - loss: 5.0555 - accuracy: 0.0832\n",
      "Epoch 243/1000\n",
      "276/276 - 70s - loss: 5.0085 - accuracy: 0.0854\n",
      "Epoch 244/1000\n",
      "276/276 - 70s - loss: 4.9632 - accuracy: 0.0887\n",
      "Epoch 245/1000\n",
      "276/276 - 70s - loss: 4.9195 - accuracy: 0.0920\n",
      "Epoch 246/1000\n",
      "276/276 - 70s - loss: 4.8884 - accuracy: 0.0937\n",
      "Epoch 247/1000\n",
      "276/276 - 70s - loss: 4.8605 - accuracy: 0.0959\n",
      "Epoch 248/1000\n",
      "276/276 - 70s - loss: 4.8347 - accuracy: 0.0988\n",
      "Epoch 249/1000\n",
      "276/276 - 70s - loss: 4.8131 - accuracy: 0.1006\n",
      "Epoch 250/1000\n",
      "276/276 - 70s - loss: 4.7811 - accuracy: 0.1032\n",
      "Epoch 251/1000\n",
      "276/276 - 70s - loss: 4.7532 - accuracy: 0.1062\n",
      "Epoch 252/1000\n",
      "276/276 - 70s - loss: 4.7249 - accuracy: 0.1082\n",
      "Epoch 253/1000\n",
      "276/276 - 70s - loss: 4.6915 - accuracy: 0.1122\n",
      "Epoch 254/1000\n",
      "276/276 - 70s - loss: 4.6605 - accuracy: 0.1149\n",
      "Epoch 255/1000\n",
      "276/276 - 70s - loss: 4.6260 - accuracy: 0.1175\n",
      "Epoch 256/1000\n",
      "276/276 - 70s - loss: 4.5925 - accuracy: 0.1213\n",
      "Epoch 257/1000\n",
      "276/276 - 70s - loss: 4.5590 - accuracy: 0.1239\n",
      "Epoch 258/1000\n",
      "276/276 - 70s - loss: 4.5292 - accuracy: 0.1268\n",
      "Epoch 259/1000\n",
      "276/276 - 70s - loss: 4.5063 - accuracy: 0.1298\n",
      "Epoch 260/1000\n",
      "276/276 - 69s - loss: 4.4738 - accuracy: 0.1330\n",
      "Epoch 261/1000\n",
      "276/276 - 69s - loss: 4.4476 - accuracy: 0.1363\n",
      "Epoch 262/1000\n",
      "276/276 - 69s - loss: 4.4217 - accuracy: 0.1378\n",
      "Epoch 263/1000\n",
      "276/276 - 69s - loss: 4.3911 - accuracy: 0.1408\n",
      "Epoch 264/1000\n",
      "276/276 - 69s - loss: 4.3613 - accuracy: 0.1449\n",
      "Epoch 265/1000\n",
      "276/276 - 69s - loss: 4.3369 - accuracy: 0.1468\n",
      "Epoch 266/1000\n",
      "276/276 - 69s - loss: 4.3116 - accuracy: 0.1503\n",
      "Epoch 267/1000\n",
      "276/276 - 69s - loss: 4.2860 - accuracy: 0.1530\n",
      "Epoch 268/1000\n",
      "276/276 - 69s - loss: 4.2612 - accuracy: 0.1563\n",
      "Epoch 269/1000\n",
      "276/276 - 68s - loss: 4.2350 - accuracy: 0.1590\n",
      "Epoch 270/1000\n",
      "276/276 - 68s - loss: 4.2117 - accuracy: 0.1623\n",
      "Epoch 271/1000\n",
      "276/276 - 68s - loss: 4.1794 - accuracy: 0.1657\n",
      "Epoch 272/1000\n",
      "276/276 - 68s - loss: 4.1497 - accuracy: 0.1701\n",
      "Epoch 273/1000\n",
      "276/276 - 68s - loss: 4.1159 - accuracy: 0.1746\n",
      "Epoch 274/1000\n",
      "276/276 - 68s - loss: 4.0868 - accuracy: 0.1784\n",
      "Epoch 275/1000\n",
      "276/276 - 68s - loss: 4.0581 - accuracy: 0.1829\n",
      "Epoch 276/1000\n",
      "276/276 - 68s - loss: 4.0313 - accuracy: 0.1860\n",
      "Epoch 277/1000\n",
      "276/276 - 67s - loss: 4.0019 - accuracy: 0.1898\n",
      "Epoch 278/1000\n",
      "276/276 - 67s - loss: 3.9790 - accuracy: 0.1932\n",
      "Epoch 279/1000\n",
      "276/276 - 67s - loss: 3.9479 - accuracy: 0.1969\n",
      "Epoch 280/1000\n",
      "276/276 - 67s - loss: 3.9213 - accuracy: 0.2012\n",
      "Epoch 281/1000\n",
      "276/276 - 67s - loss: 3.8929 - accuracy: 0.2049\n",
      "Epoch 282/1000\n",
      "276/276 - 67s - loss: 3.8678 - accuracy: 0.2077\n",
      "Epoch 283/1000\n",
      "276/276 - 67s - loss: 3.8336 - accuracy: 0.2129\n",
      "Epoch 284/1000\n",
      "276/276 - 67s - loss: 3.8092 - accuracy: 0.2162\n",
      "Epoch 285/1000\n",
      "276/276 - 67s - loss: 3.7987 - accuracy: 0.2171\n",
      "Epoch 286/1000\n",
      "276/276 - 67s - loss: 3.7641 - accuracy: 0.2224\n",
      "Epoch 287/1000\n",
      "276/276 - 68s - loss: 3.7336 - accuracy: 0.2279\n",
      "Epoch 288/1000\n",
      "276/276 - 68s - loss: 3.7001 - accuracy: 0.2331\n",
      "Epoch 289/1000\n",
      "276/276 - 68s - loss: 3.6724 - accuracy: 0.2373\n",
      "Epoch 290/1000\n",
      "276/276 - 68s - loss: 3.6437 - accuracy: 0.2413\n",
      "Epoch 291/1000\n",
      "276/276 - 68s - loss: 3.6135 - accuracy: 0.2463\n",
      "Epoch 292/1000\n",
      "276/276 - 68s - loss: 3.5862 - accuracy: 0.2500\n",
      "Epoch 293/1000\n",
      "276/276 - 69s - loss: 3.5604 - accuracy: 0.2538\n",
      "Epoch 294/1000\n",
      "276/276 - 69s - loss: 3.5352 - accuracy: 0.2577\n",
      "Epoch 295/1000\n",
      "276/276 - 69s - loss: 3.5123 - accuracy: 0.2620\n",
      "Epoch 296/1000\n",
      "276/276 - 69s - loss: 3.4793 - accuracy: 0.2664\n",
      "Epoch 297/1000\n",
      "276/276 - 69s - loss: 3.4458 - accuracy: 0.2720\n",
      "Epoch 298/1000\n",
      "276/276 - 70s - loss: 3.4194 - accuracy: 0.2761\n",
      "Epoch 299/1000\n",
      "276/276 - 70s - loss: 3.3867 - accuracy: 0.2827\n",
      "Epoch 300/1000\n",
      "276/276 - 70s - loss: 3.3663 - accuracy: 0.2849\n",
      "Epoch 301/1000\n",
      "276/276 - 70s - loss: 3.3340 - accuracy: 0.2905\n",
      "Epoch 302/1000\n",
      "276/276 - 70s - loss: 3.3036 - accuracy: 0.2953\n",
      "Epoch 303/1000\n",
      "276/276 - 70s - loss: 3.2768 - accuracy: 0.2991\n",
      "Epoch 304/1000\n",
      "276/276 - 70s - loss: 3.2443 - accuracy: 0.3069\n",
      "Epoch 305/1000\n",
      "276/276 - 70s - loss: 3.2228 - accuracy: 0.3091\n",
      "Epoch 306/1000\n",
      "276/276 - 70s - loss: 3.1986 - accuracy: 0.3137\n",
      "Epoch 307/1000\n",
      "276/276 - 70s - loss: 3.1716 - accuracy: 0.3183\n",
      "Epoch 308/1000\n",
      "276/276 - 70s - loss: 3.1496 - accuracy: 0.3222\n",
      "Epoch 309/1000\n",
      "276/276 - 70s - loss: 3.1181 - accuracy: 0.3285\n",
      "Epoch 310/1000\n",
      "276/276 - 70s - loss: 3.0947 - accuracy: 0.3322\n",
      "Epoch 311/1000\n",
      "276/276 - 70s - loss: 3.0703 - accuracy: 0.3363\n",
      "Epoch 312/1000\n",
      "276/276 - 70s - loss: 3.0387 - accuracy: 0.3422\n",
      "Epoch 313/1000\n",
      "276/276 - 70s - loss: 3.0133 - accuracy: 0.3464\n",
      "Epoch 314/1000\n",
      "276/276 - 70s - loss: 2.9854 - accuracy: 0.3517\n",
      "Epoch 315/1000\n",
      "276/276 - 70s - loss: 2.9659 - accuracy: 0.3566\n",
      "Epoch 316/1000\n",
      "276/276 - 70s - loss: 2.9405 - accuracy: 0.3598\n",
      "Epoch 317/1000\n",
      "276/276 - 70s - loss: 2.9097 - accuracy: 0.3669\n",
      "Epoch 318/1000\n",
      "276/276 - 70s - loss: 2.8857 - accuracy: 0.3711\n",
      "Epoch 319/1000\n",
      "276/276 - 70s - loss: 2.8692 - accuracy: 0.3745\n",
      "Epoch 320/1000\n",
      "276/276 - 70s - loss: 2.8504 - accuracy: 0.3769\n",
      "Epoch 321/1000\n",
      "276/276 - 70s - loss: 2.8194 - accuracy: 0.3828\n",
      "Epoch 322/1000\n",
      "276/276 - 69s - loss: 2.7866 - accuracy: 0.3893\n",
      "Epoch 323/1000\n",
      "276/276 - 69s - loss: 2.7642 - accuracy: 0.3942\n",
      "Epoch 324/1000\n",
      "276/276 - 69s - loss: 2.7484 - accuracy: 0.3976\n",
      "Epoch 325/1000\n",
      "276/276 - 69s - loss: 2.7182 - accuracy: 0.4025\n",
      "Epoch 326/1000\n",
      "276/276 - 69s - loss: 2.7037 - accuracy: 0.4048\n",
      "Epoch 327/1000\n",
      "276/276 - 69s - loss: 2.6741 - accuracy: 0.4104\n",
      "Epoch 328/1000\n",
      "276/276 - 69s - loss: 2.6525 - accuracy: 0.4150\n",
      "Epoch 329/1000\n",
      "276/276 - 69s - loss: 2.6308 - accuracy: 0.4178\n",
      "Epoch 330/1000\n",
      "276/276 - 68s - loss: 2.6140 - accuracy: 0.4219\n",
      "Epoch 331/1000\n",
      "276/276 - 68s - loss: 2.5900 - accuracy: 0.4274\n",
      "Epoch 332/1000\n",
      "276/276 - 68s - loss: 2.5690 - accuracy: 0.4311\n",
      "Epoch 333/1000\n",
      "276/276 - 68s - loss: 2.5441 - accuracy: 0.4356\n",
      "Epoch 334/1000\n",
      "276/276 - 68s - loss: 2.5160 - accuracy: 0.4404\n",
      "Epoch 335/1000\n",
      "276/276 - 68s - loss: 2.4902 - accuracy: 0.4465\n",
      "Epoch 336/1000\n",
      "276/276 - 68s - loss: 2.4685 - accuracy: 0.4505\n",
      "Epoch 337/1000\n",
      "276/276 - 68s - loss: 2.4468 - accuracy: 0.4552\n",
      "Epoch 338/1000\n",
      "276/276 - 68s - loss: 2.4240 - accuracy: 0.4602\n",
      "Epoch 339/1000\n",
      "276/276 - 67s - loss: 2.4098 - accuracy: 0.4616\n",
      "Epoch 340/1000\n",
      "276/276 - 67s - loss: 2.4042 - accuracy: 0.4628\n",
      "Epoch 341/1000\n",
      "276/276 - 67s - loss: 2.3758 - accuracy: 0.4676\n",
      "Epoch 342/1000\n",
      "276/276 - 67s - loss: 2.3488 - accuracy: 0.4734\n",
      "Epoch 343/1000\n",
      "276/276 - 67s - loss: 2.3313 - accuracy: 0.4767\n",
      "Epoch 344/1000\n",
      "276/276 - 67s - loss: 2.3236 - accuracy: 0.4783\n",
      "Epoch 345/1000\n",
      "276/276 - 67s - loss: 2.2979 - accuracy: 0.4834\n",
      "Epoch 346/1000\n",
      "276/276 - 67s - loss: 2.2819 - accuracy: 0.4870\n",
      "Epoch 347/1000\n",
      "276/276 - 67s - loss: 2.2501 - accuracy: 0.4939\n",
      "Epoch 348/1000\n",
      "276/276 - 67s - loss: 2.2324 - accuracy: 0.4977\n",
      "Epoch 349/1000\n",
      "276/276 - 68s - loss: 2.2052 - accuracy: 0.5024\n",
      "Epoch 350/1000\n",
      "276/276 - 68s - loss: 2.1917 - accuracy: 0.5064\n",
      "Epoch 351/1000\n",
      "276/276 - 68s - loss: 2.1672 - accuracy: 0.5116\n",
      "Epoch 352/1000\n",
      "276/276 - 68s - loss: 2.1583 - accuracy: 0.5123\n",
      "Epoch 353/1000\n",
      "276/276 - 68s - loss: 2.1392 - accuracy: 0.5149\n",
      "Epoch 354/1000\n",
      "276/276 - 68s - loss: 2.1351 - accuracy: 0.5162\n",
      "Epoch 355/1000\n",
      "276/276 - 68s - loss: 2.1212 - accuracy: 0.5200\n",
      "Epoch 356/1000\n",
      "276/276 - 69s - loss: 2.0986 - accuracy: 0.5241\n",
      "Epoch 357/1000\n",
      "276/276 - 69s - loss: 2.0772 - accuracy: 0.5290\n",
      "Epoch 358/1000\n",
      "276/276 - 69s - loss: 2.0518 - accuracy: 0.5328\n",
      "Epoch 359/1000\n",
      "276/276 - 69s - loss: 2.0366 - accuracy: 0.5363\n",
      "Epoch 360/1000\n",
      "276/276 - 70s - loss: 2.0192 - accuracy: 0.5421\n",
      "Epoch 361/1000\n",
      "276/276 - 70s - loss: 1.9981 - accuracy: 0.5446\n",
      "Epoch 362/1000\n",
      "276/276 - 70s - loss: 1.9837 - accuracy: 0.5473\n",
      "Epoch 363/1000\n",
      "276/276 - 70s - loss: 1.9683 - accuracy: 0.5512\n",
      "Epoch 364/1000\n",
      "276/276 - 70s - loss: 1.9540 - accuracy: 0.5540\n",
      "Epoch 365/1000\n",
      "276/276 - 70s - loss: 1.9447 - accuracy: 0.5558\n",
      "Epoch 366/1000\n",
      "276/276 - 70s - loss: 1.9260 - accuracy: 0.5581\n",
      "Epoch 367/1000\n",
      "276/276 - 70s - loss: 1.9101 - accuracy: 0.5614\n",
      "Epoch 368/1000\n",
      "276/276 - 70s - loss: 1.8810 - accuracy: 0.5676\n",
      "Epoch 369/1000\n",
      "276/276 - 70s - loss: 1.8742 - accuracy: 0.5689\n",
      "Epoch 370/1000\n",
      "276/276 - 70s - loss: 1.8515 - accuracy: 0.5745\n",
      "Epoch 371/1000\n",
      "276/276 - 70s - loss: 1.8410 - accuracy: 0.5760\n",
      "Epoch 372/1000\n",
      "276/276 - 70s - loss: 1.8218 - accuracy: 0.5822\n",
      "Epoch 373/1000\n",
      "276/276 - 70s - loss: 1.8095 - accuracy: 0.5828\n",
      "Epoch 374/1000\n",
      "276/276 - 70s - loss: 1.7932 - accuracy: 0.5866\n",
      "Epoch 375/1000\n",
      "276/276 - 70s - loss: 1.7747 - accuracy: 0.5902\n",
      "Epoch 376/1000\n",
      "276/276 - 70s - loss: 1.7638 - accuracy: 0.5929\n",
      "Epoch 377/1000\n",
      "276/276 - 70s - loss: 1.7535 - accuracy: 0.5948\n",
      "Epoch 378/1000\n",
      "276/276 - 70s - loss: 1.7400 - accuracy: 0.5981\n",
      "Epoch 379/1000\n",
      "276/276 - 70s - loss: 1.7347 - accuracy: 0.5968\n",
      "Epoch 380/1000\n",
      "276/276 - 70s - loss: 1.7144 - accuracy: 0.6036\n",
      "Epoch 381/1000\n",
      "276/276 - 70s - loss: 1.7034 - accuracy: 0.6045\n",
      "Epoch 382/1000\n",
      "276/276 - 69s - loss: 1.6747 - accuracy: 0.6112\n",
      "Epoch 383/1000\n",
      "276/276 - 69s - loss: 1.6682 - accuracy: 0.6126\n",
      "Epoch 384/1000\n",
      "276/276 - 69s - loss: 1.6449 - accuracy: 0.6175\n",
      "Epoch 385/1000\n",
      "276/276 - 69s - loss: 1.6384 - accuracy: 0.6185\n",
      "Epoch 386/1000\n",
      "276/276 - 69s - loss: 1.6367 - accuracy: 0.6204\n",
      "Epoch 387/1000\n",
      "276/276 - 69s - loss: 1.6181 - accuracy: 0.6243\n",
      "Epoch 388/1000\n",
      "276/276 - 69s - loss: 1.6108 - accuracy: 0.6253\n",
      "Epoch 389/1000\n",
      "276/276 - 68s - loss: 1.5823 - accuracy: 0.6308\n",
      "Epoch 390/1000\n",
      "276/276 - 68s - loss: 1.5686 - accuracy: 0.6341\n",
      "Epoch 391/1000\n",
      "276/276 - 68s - loss: 1.5804 - accuracy: 0.6314\n",
      "Epoch 392/1000\n",
      "276/276 - 68s - loss: 1.5748 - accuracy: 0.6306\n",
      "Epoch 393/1000\n",
      "276/276 - 68s - loss: 1.5541 - accuracy: 0.6368\n",
      "Epoch 394/1000\n",
      "276/276 - 68s - loss: 1.5342 - accuracy: 0.6401\n",
      "Epoch 395/1000\n",
      "276/276 - 68s - loss: 1.5286 - accuracy: 0.6411\n",
      "Epoch 396/1000\n",
      "276/276 - 68s - loss: 1.5069 - accuracy: 0.6461\n",
      "Epoch 397/1000\n",
      "276/276 - 68s - loss: 1.4904 - accuracy: 0.6520\n",
      "Epoch 398/1000\n",
      "276/276 - 67s - loss: 1.4953 - accuracy: 0.6483\n",
      "Epoch 399/1000\n",
      "276/276 - 67s - loss: 1.4936 - accuracy: 0.6481\n",
      "Epoch 400/1000\n",
      "276/276 - 67s - loss: 1.4778 - accuracy: 0.6515\n",
      "Epoch 401/1000\n",
      "276/276 - 67s - loss: 1.4435 - accuracy: 0.6594\n",
      "Epoch 402/1000\n",
      "276/276 - 67s - loss: 1.4340 - accuracy: 0.6614\n",
      "Epoch 403/1000\n",
      "276/276 - 67s - loss: 1.4374 - accuracy: 0.6600\n",
      "Epoch 404/1000\n",
      "276/276 - 67s - loss: 1.4162 - accuracy: 0.6648\n",
      "Epoch 405/1000\n",
      "276/276 - 67s - loss: 1.4018 - accuracy: 0.6686\n",
      "Epoch 406/1000\n",
      "276/276 - 67s - loss: 1.3932 - accuracy: 0.6709\n",
      "Epoch 407/1000\n",
      "276/276 - 67s - loss: 1.3856 - accuracy: 0.6734\n",
      "Epoch 408/1000\n",
      "276/276 - 67s - loss: 1.3637 - accuracy: 0.6785\n",
      "Epoch 409/1000\n",
      "276/276 - 68s - loss: 1.3570 - accuracy: 0.6797\n",
      "Epoch 410/1000\n",
      "276/276 - 68s - loss: 1.3487 - accuracy: 0.6801\n",
      "Epoch 411/1000\n",
      "276/276 - 68s - loss: 1.3479 - accuracy: 0.6794\n",
      "Epoch 412/1000\n",
      "276/276 - 68s - loss: 1.3293 - accuracy: 0.6843\n",
      "Epoch 413/1000\n",
      "276/276 - 68s - loss: 1.3171 - accuracy: 0.6871\n",
      "Epoch 414/1000\n",
      "276/276 - 68s - loss: 1.3094 - accuracy: 0.6892\n",
      "Epoch 415/1000\n",
      "276/276 - 68s - loss: 1.3032 - accuracy: 0.6921\n",
      "Epoch 416/1000\n",
      "276/276 - 69s - loss: 1.2968 - accuracy: 0.6907\n",
      "Epoch 417/1000\n",
      "276/276 - 69s - loss: 1.2841 - accuracy: 0.6937\n",
      "Epoch 418/1000\n",
      "276/276 - 69s - loss: 1.2870 - accuracy: 0.6923\n",
      "Epoch 419/1000\n",
      "276/276 - 69s - loss: 1.2799 - accuracy: 0.6938\n",
      "Epoch 420/1000\n",
      "276/276 - 70s - loss: 1.2643 - accuracy: 0.6988\n",
      "Epoch 421/1000\n",
      "276/276 - 70s - loss: 1.2590 - accuracy: 0.6973\n",
      "Epoch 422/1000\n",
      "276/276 - 70s - loss: 1.2336 - accuracy: 0.7044\n",
      "Epoch 423/1000\n",
      "276/276 - 70s - loss: 1.2356 - accuracy: 0.7035\n",
      "Epoch 424/1000\n",
      "276/276 - 70s - loss: 1.2188 - accuracy: 0.7081\n",
      "Epoch 425/1000\n",
      "276/276 - 70s - loss: 1.2078 - accuracy: 0.7101\n",
      "Epoch 426/1000\n",
      "276/276 - 71s - loss: 1.2027 - accuracy: 0.7113\n",
      "Epoch 427/1000\n",
      "276/276 - 71s - loss: 1.2016 - accuracy: 0.7120\n",
      "Epoch 428/1000\n",
      "276/276 - 71s - loss: 1.2038 - accuracy: 0.7115\n",
      "Epoch 429/1000\n",
      "276/276 - 71s - loss: 1.1857 - accuracy: 0.7155\n",
      "Epoch 430/1000\n",
      "276/276 - 71s - loss: 1.1719 - accuracy: 0.7192\n",
      "Epoch 431/1000\n",
      "276/276 - 71s - loss: 1.1695 - accuracy: 0.7181\n",
      "Epoch 432/1000\n",
      "276/276 - 71s - loss: 1.1634 - accuracy: 0.7195\n",
      "Epoch 433/1000\n",
      "276/276 - 71s - loss: 1.1588 - accuracy: 0.7211\n",
      "Epoch 434/1000\n",
      "276/276 - 71s - loss: 1.1434 - accuracy: 0.7254\n",
      "Epoch 435/1000\n",
      "276/276 - 70s - loss: 1.1276 - accuracy: 0.7284\n",
      "Epoch 436/1000\n",
      "276/276 - 70s - loss: 1.1237 - accuracy: 0.7276\n",
      "Epoch 437/1000\n",
      "276/276 - 70s - loss: 1.1103 - accuracy: 0.7332\n",
      "Epoch 438/1000\n",
      "276/276 - 70s - loss: 1.1004 - accuracy: 0.7334\n",
      "Epoch 439/1000\n",
      "276/276 - 70s - loss: 1.1106 - accuracy: 0.7318\n",
      "Epoch 440/1000\n",
      "276/276 - 70s - loss: 1.1006 - accuracy: 0.7327\n",
      "Epoch 441/1000\n",
      "276/276 - 71s - loss: 1.1127 - accuracy: 0.7278\n",
      "Epoch 442/1000\n",
      "276/276 - 70s - loss: 1.0729 - accuracy: 0.7402\n",
      "Epoch 443/1000\n",
      "276/276 - 70s - loss: 1.0746 - accuracy: 0.7372\n",
      "Epoch 444/1000\n",
      "276/276 - 70s - loss: 1.0683 - accuracy: 0.7407\n",
      "Epoch 445/1000\n",
      "276/276 - 70s - loss: 1.0588 - accuracy: 0.7416\n",
      "Epoch 446/1000\n",
      "276/276 - 70s - loss: 1.0569 - accuracy: 0.7422\n",
      "Epoch 447/1000\n",
      "276/276 - 70s - loss: 1.0485 - accuracy: 0.7437\n",
      "Epoch 448/1000\n",
      "276/276 - 70s - loss: 1.0357 - accuracy: 0.7470\n",
      "Epoch 449/1000\n",
      "276/276 - 69s - loss: 1.0270 - accuracy: 0.7495\n",
      "Epoch 450/1000\n",
      "276/276 - 69s - loss: 1.0247 - accuracy: 0.7496\n",
      "Epoch 451/1000\n",
      "276/276 - 69s - loss: 1.0313 - accuracy: 0.7468\n",
      "Epoch 452/1000\n",
      "276/276 - 69s - loss: 1.0195 - accuracy: 0.7511\n",
      "Epoch 453/1000\n",
      "276/276 - 69s - loss: 1.0145 - accuracy: 0.7520\n",
      "Epoch 454/1000\n",
      "276/276 - 69s - loss: 1.0164 - accuracy: 0.7513\n",
      "Epoch 455/1000\n",
      "276/276 - 69s - loss: 1.0165 - accuracy: 0.7501\n",
      "Epoch 456/1000\n",
      "276/276 - 69s - loss: 0.9968 - accuracy: 0.7560\n",
      "Epoch 457/1000\n",
      "276/276 - 69s - loss: 0.9921 - accuracy: 0.7570\n",
      "Epoch 458/1000\n",
      "276/276 - 69s - loss: 0.9679 - accuracy: 0.7627\n",
      "Epoch 459/1000\n",
      "276/276 - 69s - loss: 0.9801 - accuracy: 0.7584\n",
      "Epoch 460/1000\n",
      "276/276 - 69s - loss: 0.9746 - accuracy: 0.7601\n",
      "Epoch 461/1000\n",
      "276/276 - 69s - loss: 0.9754 - accuracy: 0.7604\n",
      "Epoch 462/1000\n",
      "276/276 - 69s - loss: 0.9641 - accuracy: 0.7633\n",
      "Epoch 463/1000\n",
      "276/276 - 69s - loss: 0.9623 - accuracy: 0.7628\n",
      "Epoch 464/1000\n",
      "276/276 - 69s - loss: 0.9522 - accuracy: 0.7643\n",
      "Epoch 465/1000\n",
      "276/276 - 69s - loss: 0.9500 - accuracy: 0.7650\n",
      "Epoch 466/1000\n",
      "276/276 - 68s - loss: 0.9401 - accuracy: 0.7678\n",
      "Epoch 467/1000\n",
      "276/276 - 68s - loss: 0.9220 - accuracy: 0.7721\n",
      "Epoch 468/1000\n",
      "276/276 - 68s - loss: 0.9116 - accuracy: 0.7743\n",
      "Epoch 469/1000\n",
      "276/276 - 68s - loss: 0.9187 - accuracy: 0.7726\n",
      "Epoch 470/1000\n",
      "276/276 - 68s - loss: 0.9091 - accuracy: 0.7757\n",
      "Epoch 471/1000\n",
      "276/276 - 68s - loss: 0.9020 - accuracy: 0.7769\n",
      "Epoch 472/1000\n",
      "276/276 - 68s - loss: 0.9062 - accuracy: 0.7766\n",
      "Epoch 473/1000\n",
      "276/276 - 68s - loss: 0.9106 - accuracy: 0.7745\n",
      "Epoch 474/1000\n",
      "276/276 - 68s - loss: 0.9013 - accuracy: 0.7755\n",
      "Epoch 475/1000\n",
      "276/276 - 68s - loss: 0.9037 - accuracy: 0.7742\n",
      "Epoch 476/1000\n",
      "276/276 - 68s - loss: 0.8966 - accuracy: 0.7760\n",
      "Epoch 477/1000\n",
      "276/276 - 68s - loss: 0.8924 - accuracy: 0.7773\n",
      "Epoch 478/1000\n",
      "276/276 - 68s - loss: 0.8946 - accuracy: 0.7768\n",
      "Epoch 479/1000\n",
      "276/276 - 68s - loss: 0.8772 - accuracy: 0.7800\n",
      "Epoch 480/1000\n",
      "276/276 - 68s - loss: 0.8818 - accuracy: 0.7798\n",
      "Epoch 481/1000\n",
      "276/276 - 68s - loss: 0.8755 - accuracy: 0.7822\n",
      "Epoch 482/1000\n",
      "276/276 - 68s - loss: 0.8715 - accuracy: 0.7837\n",
      "Epoch 483/1000\n",
      "276/276 - 68s - loss: 0.8673 - accuracy: 0.7821\n",
      "Epoch 484/1000\n",
      "276/276 - 68s - loss: 0.8463 - accuracy: 0.7889\n",
      "Epoch 485/1000\n",
      "276/276 - 68s - loss: 0.8448 - accuracy: 0.7894\n",
      "Epoch 486/1000\n",
      "276/276 - 68s - loss: 0.8481 - accuracy: 0.7871\n",
      "Epoch 487/1000\n",
      "276/276 - 68s - loss: 0.8509 - accuracy: 0.7860\n",
      "Epoch 488/1000\n",
      "276/276 - 68s - loss: 0.8312 - accuracy: 0.7914\n",
      "Epoch 489/1000\n",
      "276/276 - 68s - loss: 0.8370 - accuracy: 0.7895\n",
      "Epoch 490/1000\n",
      "276/276 - 68s - loss: 0.8396 - accuracy: 0.7883\n",
      "Epoch 491/1000\n",
      "276/276 - 68s - loss: 0.8330 - accuracy: 0.7905\n",
      "Epoch 492/1000\n",
      "276/276 - 68s - loss: 0.8222 - accuracy: 0.7934\n",
      "Epoch 493/1000\n",
      "276/276 - 68s - loss: 0.8189 - accuracy: 0.7925\n",
      "Epoch 494/1000\n",
      "276/276 - 68s - loss: 0.8034 - accuracy: 0.7980\n",
      "Epoch 495/1000\n",
      "276/276 - 68s - loss: 0.8065 - accuracy: 0.7976\n",
      "Epoch 496/1000\n",
      "276/276 - 68s - loss: 0.7908 - accuracy: 0.8012\n",
      "Epoch 497/1000\n",
      "276/276 - 68s - loss: 0.7858 - accuracy: 0.8024\n",
      "Epoch 498/1000\n",
      "276/276 - 68s - loss: 0.7960 - accuracy: 0.7995\n",
      "Epoch 499/1000\n",
      "276/276 - 68s - loss: 0.8005 - accuracy: 0.7975\n",
      "Epoch 500/1000\n",
      "276/276 - 68s - loss: 0.7859 - accuracy: 0.8023\n",
      "Epoch 501/1000\n",
      "276/276 - 68s - loss: 0.7858 - accuracy: 0.8025\n",
      "Epoch 502/1000\n",
      "276/276 - 68s - loss: 0.7752 - accuracy: 0.8049\n",
      "Epoch 503/1000\n",
      "276/276 - 68s - loss: 0.7739 - accuracy: 0.8060\n",
      "Epoch 504/1000\n",
      "276/276 - 68s - loss: 0.7831 - accuracy: 0.8029\n",
      "Epoch 505/1000\n",
      "276/276 - 68s - loss: 0.7761 - accuracy: 0.8027\n",
      "Epoch 506/1000\n",
      "276/276 - 68s - loss: 0.7708 - accuracy: 0.8053\n",
      "Epoch 507/1000\n",
      "276/276 - 68s - loss: 0.7682 - accuracy: 0.8040\n",
      "Epoch 508/1000\n",
      "276/276 - 68s - loss: 0.7544 - accuracy: 0.8088\n",
      "Epoch 509/1000\n",
      "276/276 - 68s - loss: 0.7486 - accuracy: 0.8105\n",
      "Epoch 510/1000\n",
      "276/276 - 68s - loss: 0.7756 - accuracy: 0.8018\n",
      "Epoch 511/1000\n",
      "276/276 - 68s - loss: 0.7660 - accuracy: 0.8065\n",
      "Epoch 512/1000\n",
      "276/276 - 68s - loss: 0.7654 - accuracy: 0.8056\n",
      "Epoch 513/1000\n",
      "276/276 - 68s - loss: 0.7572 - accuracy: 0.8077\n",
      "Epoch 514/1000\n",
      "276/276 - 68s - loss: 0.7399 - accuracy: 0.8117\n",
      "Epoch 515/1000\n",
      "276/276 - 68s - loss: 0.7458 - accuracy: 0.8105\n",
      "Epoch 516/1000\n",
      "276/276 - 68s - loss: 0.7457 - accuracy: 0.8097\n",
      "Epoch 517/1000\n",
      "276/276 - 68s - loss: 0.7321 - accuracy: 0.8138\n",
      "Epoch 518/1000\n",
      "276/276 - 68s - loss: 0.7406 - accuracy: 0.8111\n",
      "Epoch 519/1000\n",
      "276/276 - 68s - loss: 0.7408 - accuracy: 0.8109\n",
      "Epoch 520/1000\n",
      "276/276 - 68s - loss: 0.7316 - accuracy: 0.8128\n",
      "Epoch 521/1000\n",
      "276/276 - 69s - loss: 0.7208 - accuracy: 0.8157\n",
      "Epoch 522/1000\n",
      "276/276 - 70s - loss: 0.7174 - accuracy: 0.8159\n",
      "Epoch 523/1000\n",
      "276/276 - 70s - loss: 0.7168 - accuracy: 0.8166\n",
      "Epoch 524/1000\n",
      "276/276 - 70s - loss: 0.7069 - accuracy: 0.8191\n",
      "Epoch 525/1000\n",
      "276/276 - 71s - loss: 0.7149 - accuracy: 0.8191\n",
      "Epoch 526/1000\n",
      "276/276 - 71s - loss: 0.7107 - accuracy: 0.8182\n",
      "Epoch 527/1000\n",
      "276/276 - 71s - loss: 0.7299 - accuracy: 0.8125\n",
      "Epoch 528/1000\n",
      "276/276 - 71s - loss: 0.7158 - accuracy: 0.8169\n",
      "Epoch 529/1000\n",
      "276/276 - 71s - loss: 0.7182 - accuracy: 0.8152\n",
      "Epoch 530/1000\n",
      "276/276 - 71s - loss: 0.7070 - accuracy: 0.8195\n",
      "Epoch 531/1000\n",
      "276/276 - 71s - loss: 0.7183 - accuracy: 0.8157\n",
      "Epoch 532/1000\n",
      "276/276 - 70s - loss: 0.7129 - accuracy: 0.8185\n",
      "Epoch 533/1000\n",
      "276/276 - 70s - loss: 0.6995 - accuracy: 0.8203\n",
      "Epoch 534/1000\n",
      "276/276 - 71s - loss: 0.6995 - accuracy: 0.8216\n",
      "Epoch 535/1000\n",
      "276/276 - 71s - loss: 0.6866 - accuracy: 0.8243\n",
      "Epoch 536/1000\n",
      "276/276 - 70s - loss: 0.6941 - accuracy: 0.8220\n",
      "Epoch 537/1000\n",
      "276/276 - 70s - loss: 0.6991 - accuracy: 0.8214\n",
      "Epoch 538/1000\n",
      "276/276 - 70s - loss: 0.6963 - accuracy: 0.8215\n",
      "Epoch 539/1000\n",
      "276/276 - 71s - loss: 0.6860 - accuracy: 0.8249\n",
      "Epoch 540/1000\n",
      "276/276 - 70s - loss: 0.6868 - accuracy: 0.8237\n",
      "Epoch 541/1000\n",
      "276/276 - 70s - loss: 0.6863 - accuracy: 0.8245\n",
      "Epoch 542/1000\n",
      "276/276 - 70s - loss: 0.6804 - accuracy: 0.8262\n",
      "Epoch 543/1000\n",
      "276/276 - 70s - loss: 0.6658 - accuracy: 0.8298\n",
      "Epoch 544/1000\n",
      "276/276 - 70s - loss: 0.6753 - accuracy: 0.8277\n",
      "Epoch 545/1000\n",
      "276/276 - 70s - loss: 0.6627 - accuracy: 0.8300\n",
      "Epoch 546/1000\n",
      "276/276 - 70s - loss: 0.6700 - accuracy: 0.8288\n",
      "Epoch 547/1000\n",
      "276/276 - 70s - loss: 0.6585 - accuracy: 0.8318\n",
      "Epoch 548/1000\n",
      "276/276 - 69s - loss: 0.6738 - accuracy: 0.8282\n",
      "Epoch 549/1000\n",
      "276/276 - 69s - loss: 0.6894 - accuracy: 0.8223\n",
      "Epoch 550/1000\n",
      "276/276 - 69s - loss: 0.6892 - accuracy: 0.8210\n",
      "Epoch 551/1000\n",
      "276/276 - 69s - loss: 0.6947 - accuracy: 0.8205\n",
      "Epoch 552/1000\n",
      "276/276 - 69s - loss: 0.6790 - accuracy: 0.8260\n",
      "Epoch 553/1000\n",
      "276/276 - 69s - loss: 0.6717 - accuracy: 0.8264\n",
      "Epoch 554/1000\n",
      "276/276 - 69s - loss: 0.6641 - accuracy: 0.8280\n",
      "Epoch 555/1000\n",
      "276/276 - 69s - loss: 0.6533 - accuracy: 0.8310\n",
      "Epoch 556/1000\n",
      "276/276 - 69s - loss: 0.6464 - accuracy: 0.8326\n",
      "Epoch 557/1000\n",
      "276/276 - 69s - loss: 0.6383 - accuracy: 0.8343\n",
      "Epoch 558/1000\n",
      "276/276 - 69s - loss: 0.6308 - accuracy: 0.8365\n",
      "Epoch 559/1000\n",
      "276/276 - 69s - loss: 0.6535 - accuracy: 0.8305\n",
      "Epoch 560/1000\n",
      "276/276 - 68s - loss: 0.6642 - accuracy: 0.8262\n",
      "Epoch 561/1000\n",
      "276/276 - 68s - loss: 0.6763 - accuracy: 0.8240\n",
      "Epoch 562/1000\n",
      "276/276 - 68s - loss: 0.6745 - accuracy: 0.8244\n",
      "Epoch 563/1000\n",
      "276/276 - 68s - loss: 0.6640 - accuracy: 0.8277\n",
      "Epoch 564/1000\n",
      "276/276 - 68s - loss: 0.6558 - accuracy: 0.8288\n",
      "Epoch 565/1000\n",
      "276/276 - 68s - loss: 0.6404 - accuracy: 0.8339\n",
      "Epoch 566/1000\n",
      "276/276 - 68s - loss: 0.6238 - accuracy: 0.8397\n",
      "Epoch 567/1000\n",
      "276/276 - 68s - loss: 0.6183 - accuracy: 0.8410\n",
      "Epoch 568/1000\n",
      "276/276 - 68s - loss: 0.6251 - accuracy: 0.8391\n",
      "Epoch 569/1000\n",
      "276/276 - 68s - loss: 0.6241 - accuracy: 0.8378\n",
      "Epoch 570/1000\n",
      "276/276 - 68s - loss: 0.6370 - accuracy: 0.8331\n",
      "Epoch 571/1000\n",
      "276/276 - 68s - loss: 0.6485 - accuracy: 0.8296\n",
      "Epoch 572/1000\n",
      "276/276 - 68s - loss: 0.6231 - accuracy: 0.8374\n",
      "Epoch 573/1000\n",
      "276/276 - 68s - loss: 0.6174 - accuracy: 0.8388\n",
      "Epoch 574/1000\n",
      "276/276 - 68s - loss: 0.6159 - accuracy: 0.8386\n",
      "Epoch 575/1000\n",
      "276/276 - 68s - loss: 0.6183 - accuracy: 0.8383\n",
      "Epoch 576/1000\n",
      "276/276 - 68s - loss: 0.6211 - accuracy: 0.8356\n",
      "Epoch 577/1000\n",
      "276/276 - 68s - loss: 0.6151 - accuracy: 0.8395\n",
      "Epoch 578/1000\n",
      "276/276 - 68s - loss: 0.6208 - accuracy: 0.8371\n",
      "Epoch 579/1000\n",
      "276/276 - 68s - loss: 0.6239 - accuracy: 0.8362\n",
      "Epoch 580/1000\n",
      "276/276 - 68s - loss: 0.6145 - accuracy: 0.8395\n",
      "Epoch 581/1000\n",
      "276/276 - 68s - loss: 0.6111 - accuracy: 0.8397\n",
      "Epoch 582/1000\n",
      "276/276 - 68s - loss: 0.5948 - accuracy: 0.8438\n",
      "Epoch 583/1000\n",
      "276/276 - 68s - loss: 0.6103 - accuracy: 0.8402\n",
      "Epoch 584/1000\n",
      "276/276 - 68s - loss: 0.6069 - accuracy: 0.8408\n",
      "Epoch 585/1000\n",
      "276/276 - 68s - loss: 0.5925 - accuracy: 0.8455\n",
      "Epoch 586/1000\n",
      "276/276 - 68s - loss: 0.6169 - accuracy: 0.8394\n",
      "Epoch 587/1000\n",
      "276/276 - 68s - loss: 0.6408 - accuracy: 0.8340\n",
      "Epoch 588/1000\n",
      "276/276 - 68s - loss: 0.6359 - accuracy: 0.8345\n",
      "Epoch 589/1000\n",
      "276/276 - 68s - loss: 0.6320 - accuracy: 0.8365\n",
      "Epoch 590/1000\n",
      "276/276 - 68s - loss: 0.6120 - accuracy: 0.8408\n",
      "Epoch 591/1000\n",
      "276/276 - 68s - loss: 0.6134 - accuracy: 0.8400\n",
      "Epoch 592/1000\n",
      "276/276 - 68s - loss: 0.6060 - accuracy: 0.8410\n",
      "Epoch 593/1000\n",
      "276/276 - 68s - loss: 0.6040 - accuracy: 0.8428\n",
      "Epoch 594/1000\n",
      "276/276 - 68s - loss: 0.6113 - accuracy: 0.8422\n",
      "Epoch 595/1000\n",
      "276/276 - 68s - loss: 0.5936 - accuracy: 0.8465\n",
      "Epoch 596/1000\n",
      "276/276 - 68s - loss: 0.6101 - accuracy: 0.8424\n",
      "Epoch 597/1000\n",
      "276/276 - 68s - loss: 0.5917 - accuracy: 0.8454\n",
      "Epoch 598/1000\n",
      "276/276 - 68s - loss: 0.5775 - accuracy: 0.8508\n",
      "Epoch 599/1000\n",
      "276/276 - 68s - loss: 0.5802 - accuracy: 0.8503\n",
      "Epoch 600/1000\n",
      "276/276 - 68s - loss: 0.6000 - accuracy: 0.8440\n",
      "Epoch 601/1000\n",
      "276/276 - 68s - loss: 0.5989 - accuracy: 0.8428\n",
      "Epoch 602/1000\n",
      "276/276 - 68s - loss: 0.5915 - accuracy: 0.8442\n",
      "Epoch 603/1000\n",
      "276/276 - 69s - loss: 0.5753 - accuracy: 0.8479\n",
      "Epoch 604/1000\n",
      "276/276 - 70s - loss: 0.5893 - accuracy: 0.8460\n",
      "Epoch 605/1000\n",
      "276/276 - 70s - loss: 0.6105 - accuracy: 0.8386\n",
      "Epoch 606/1000\n",
      "276/276 - 70s - loss: 0.6081 - accuracy: 0.8412\n",
      "Epoch 607/1000\n",
      "276/276 - 71s - loss: 0.6045 - accuracy: 0.8397\n",
      "Epoch 608/1000\n",
      "276/276 - 71s - loss: 0.6008 - accuracy: 0.8415\n",
      "Epoch 609/1000\n",
      "276/276 - 71s - loss: 0.5790 - accuracy: 0.8481\n",
      "Epoch 610/1000\n",
      "276/276 - 71s - loss: 0.5771 - accuracy: 0.8475\n",
      "Epoch 611/1000\n",
      "276/276 - 71s - loss: 0.5715 - accuracy: 0.8475\n",
      "Epoch 612/1000\n",
      "276/276 - 71s - loss: 0.5934 - accuracy: 0.8445\n",
      "Epoch 613/1000\n",
      "276/276 - 71s - loss: 0.6025 - accuracy: 0.8421\n",
      "Epoch 614/1000\n",
      "276/276 - 70s - loss: 0.5920 - accuracy: 0.8454\n",
      "Epoch 615/1000\n",
      "276/276 - 71s - loss: 0.5632 - accuracy: 0.8522\n",
      "Epoch 616/1000\n",
      "276/276 - 70s - loss: 0.5698 - accuracy: 0.8514\n",
      "Epoch 617/1000\n",
      "276/276 - 71s - loss: 0.5690 - accuracy: 0.8508\n",
      "Epoch 618/1000\n",
      "276/276 - 70s - loss: 0.5734 - accuracy: 0.8488\n",
      "Epoch 619/1000\n",
      "276/276 - 70s - loss: 0.5766 - accuracy: 0.8485\n",
      "Epoch 620/1000\n",
      "276/276 - 70s - loss: 0.5684 - accuracy: 0.8524\n",
      "Epoch 621/1000\n",
      "276/276 - 70s - loss: 0.5655 - accuracy: 0.8517\n",
      "Epoch 622/1000\n",
      "276/276 - 70s - loss: 0.5714 - accuracy: 0.8505\n",
      "Epoch 623/1000\n",
      "276/276 - 70s - loss: 0.5549 - accuracy: 0.8543\n",
      "Epoch 624/1000\n",
      "276/276 - 70s - loss: 0.5476 - accuracy: 0.8554\n",
      "Epoch 625/1000\n",
      "276/276 - 70s - loss: 0.5518 - accuracy: 0.8557\n",
      "Epoch 626/1000\n",
      "276/276 - 70s - loss: 0.5477 - accuracy: 0.8558\n",
      "Epoch 627/1000\n",
      "276/276 - 70s - loss: 0.5534 - accuracy: 0.8544\n",
      "Epoch 628/1000\n",
      "276/276 - 70s - loss: 0.5708 - accuracy: 0.8489\n",
      "Epoch 629/1000\n",
      "276/276 - 70s - loss: 0.5730 - accuracy: 0.8493\n",
      "Epoch 630/1000\n",
      "276/276 - 70s - loss: 0.5739 - accuracy: 0.8486\n",
      "Epoch 631/1000\n",
      "276/276 - 69s - loss: 0.5623 - accuracy: 0.8528\n",
      "Epoch 632/1000\n",
      "276/276 - 69s - loss: 0.5580 - accuracy: 0.8526\n",
      "Epoch 633/1000\n",
      "276/276 - 69s - loss: 0.5555 - accuracy: 0.8537\n",
      "Epoch 634/1000\n",
      "276/276 - 69s - loss: 0.5464 - accuracy: 0.8563\n",
      "Epoch 635/1000\n",
      "276/276 - 69s - loss: 0.5538 - accuracy: 0.8537\n",
      "Epoch 636/1000\n",
      "276/276 - 69s - loss: 0.5639 - accuracy: 0.8506\n",
      "Epoch 637/1000\n",
      "276/276 - 69s - loss: 0.5704 - accuracy: 0.8491\n",
      "Epoch 638/1000\n",
      "276/276 - 69s - loss: 0.5592 - accuracy: 0.8516\n",
      "Epoch 639/1000\n",
      "276/276 - 68s - loss: 0.5419 - accuracy: 0.8569\n",
      "Epoch 640/1000\n",
      "276/276 - 68s - loss: 0.5410 - accuracy: 0.8575\n",
      "Epoch 641/1000\n",
      "276/276 - 68s - loss: 0.5442 - accuracy: 0.8556\n",
      "Epoch 642/1000\n",
      "276/276 - 68s - loss: 0.5580 - accuracy: 0.8527\n",
      "Epoch 643/1000\n",
      "276/276 - 68s - loss: 0.5633 - accuracy: 0.8502\n",
      "Epoch 644/1000\n",
      "276/276 - 68s - loss: 0.5526 - accuracy: 0.8536\n",
      "Epoch 645/1000\n",
      "276/276 - 68s - loss: 0.5700 - accuracy: 0.8494\n",
      "Epoch 646/1000\n",
      "276/276 - 68s - loss: 0.5790 - accuracy: 0.8470\n",
      "Epoch 647/1000\n",
      "276/276 - 68s - loss: 0.5719 - accuracy: 0.8482\n",
      "Epoch 648/1000\n",
      "276/276 - 68s - loss: 0.5574 - accuracy: 0.8508\n",
      "Epoch 649/1000\n",
      "276/276 - 68s - loss: 0.5360 - accuracy: 0.8579\n",
      "Epoch 650/1000\n",
      "276/276 - 68s - loss: 0.5328 - accuracy: 0.8590\n",
      "Epoch 651/1000\n",
      "276/276 - 68s - loss: 0.5317 - accuracy: 0.8597\n",
      "Epoch 652/1000\n",
      "276/276 - 68s - loss: 0.5442 - accuracy: 0.8557\n",
      "Epoch 653/1000\n",
      "276/276 - 68s - loss: 0.5363 - accuracy: 0.8578\n",
      "Epoch 654/1000\n",
      "276/276 - 68s - loss: 0.5337 - accuracy: 0.8582\n",
      "Epoch 655/1000\n",
      "276/276 - 68s - loss: 0.5354 - accuracy: 0.8579\n",
      "Epoch 656/1000\n",
      "276/276 - 68s - loss: 0.5432 - accuracy: 0.8551\n",
      "Epoch 657/1000\n",
      "276/276 - 68s - loss: 0.5468 - accuracy: 0.8536\n",
      "Epoch 658/1000\n",
      "276/276 - 68s - loss: 0.5412 - accuracy: 0.8554\n",
      "Epoch 659/1000\n",
      "276/276 - 68s - loss: 0.5349 - accuracy: 0.8571\n",
      "Epoch 660/1000\n",
      "276/276 - 68s - loss: 0.5404 - accuracy: 0.8568\n",
      "Epoch 661/1000\n",
      "276/276 - 68s - loss: 0.5625 - accuracy: 0.8492\n",
      "Epoch 662/1000\n",
      "276/276 - 68s - loss: 0.5407 - accuracy: 0.8566\n",
      "Epoch 663/1000\n",
      "276/276 - 68s - loss: 0.5383 - accuracy: 0.8567\n",
      "Epoch 664/1000\n",
      "276/276 - 68s - loss: 0.5456 - accuracy: 0.8563\n",
      "\n",
      "Epoch 00664: ReduceLROnPlateau reducing learning rate to 0.0009492187527939677.\n",
      "Epoch 665/1000\n",
      "276/276 - 68s - loss: 0.4292 - accuracy: 0.8923\n",
      "Epoch 666/1000\n",
      "276/276 - 68s - loss: 0.3162 - accuracy: 0.9279\n",
      "Epoch 667/1000\n",
      "276/276 - 68s - loss: 0.2658 - accuracy: 0.9425\n",
      "Epoch 668/1000\n",
      "276/276 - 68s - loss: 0.2350 - accuracy: 0.9509\n",
      "Epoch 669/1000\n",
      "276/276 - 68s - loss: 0.2267 - accuracy: 0.9532\n",
      "Epoch 670/1000\n",
      "276/276 - 68s - loss: 0.2363 - accuracy: 0.9490\n",
      "Epoch 671/1000\n",
      "276/276 - 68s - loss: 0.2527 - accuracy: 0.9435\n",
      "Epoch 672/1000\n",
      "276/276 - 68s - loss: 0.2706 - accuracy: 0.9367\n",
      "Epoch 673/1000\n",
      "276/276 - 68s - loss: 0.2962 - accuracy: 0.9284\n",
      "Epoch 674/1000\n",
      "276/276 - 68s - loss: 0.3155 - accuracy: 0.9216\n",
      "Epoch 675/1000\n",
      "276/276 - 69s - loss: 0.3144 - accuracy: 0.9212\n",
      "Epoch 676/1000\n",
      "276/276 - 70s - loss: 0.3100 - accuracy: 0.9234\n",
      "Epoch 677/1000\n",
      "276/276 - 70s - loss: 0.2925 - accuracy: 0.9295\n",
      "Epoch 678/1000\n",
      "276/276 - 71s - loss: 0.2936 - accuracy: 0.9281\n",
      "Epoch 679/1000\n",
      "276/276 - 71s - loss: 0.2924 - accuracy: 0.9296\n",
      "Epoch 680/1000\n",
      "276/276 - 71s - loss: 0.2893 - accuracy: 0.9300\n",
      "Epoch 681/1000\n",
      "276/276 - 71s - loss: 0.2898 - accuracy: 0.9299\n",
      "Epoch 682/1000\n",
      "276/276 - 71s - loss: 0.2919 - accuracy: 0.9289\n",
      "\n",
      "Epoch 00682: ReduceLROnPlateau reducing learning rate to 0.0007119140645954758.\n",
      "Epoch 683/1000\n",
      "276/276 - 71s - loss: 0.2198 - accuracy: 0.9526\n",
      "Epoch 684/1000\n",
      "276/276 - 71s - loss: 0.1533 - accuracy: 0.9736\n",
      "Epoch 685/1000\n",
      "276/276 - 70s - loss: 0.1265 - accuracy: 0.9814\n",
      "Epoch 686/1000\n",
      "276/276 - 70s - loss: 0.1127 - accuracy: 0.9844\n",
      "Epoch 687/1000\n",
      "276/276 - 70s - loss: 0.1031 - accuracy: 0.9865\n",
      "Epoch 688/1000\n",
      "276/276 - 70s - loss: 0.0946 - accuracy: 0.9880\n",
      "Epoch 689/1000\n",
      "276/276 - 71s - loss: 0.1007 - accuracy: 0.9860\n",
      "Epoch 690/1000\n",
      "276/276 - 70s - loss: 0.1173 - accuracy: 0.9816\n",
      "Epoch 691/1000\n",
      "276/276 - 70s - loss: 0.1490 - accuracy: 0.9710\n",
      "Epoch 692/1000\n",
      "276/276 - 70s - loss: 0.1910 - accuracy: 0.9579\n",
      "Epoch 693/1000\n",
      "276/276 - 70s - loss: 0.2003 - accuracy: 0.9550\n",
      "Epoch 694/1000\n",
      "276/276 - 70s - loss: 0.2017 - accuracy: 0.9548\n",
      "Epoch 695/1000\n",
      "276/276 - 70s - loss: 0.1817 - accuracy: 0.9606\n",
      "Epoch 696/1000\n",
      "276/276 - 70s - loss: 0.1648 - accuracy: 0.9666\n",
      "Epoch 697/1000\n",
      "276/276 - 70s - loss: 0.1432 - accuracy: 0.9730\n",
      "Epoch 698/1000\n",
      "276/276 - 70s - loss: 0.1247 - accuracy: 0.9788\n",
      "Epoch 699/1000\n",
      "276/276 - 70s - loss: 0.1164 - accuracy: 0.9818\n",
      "Epoch 700/1000\n",
      "276/276 - 70s - loss: 0.1172 - accuracy: 0.9806\n",
      "Epoch 701/1000\n",
      "276/276 - 70s - loss: 0.1242 - accuracy: 0.9790\n",
      "\n",
      "Epoch 00701: ReduceLROnPlateau reducing learning rate to 0.000533935526618734.\n",
      "Epoch 702/1000\n",
      "276/276 - 69s - loss: 0.0954 - accuracy: 0.9866\n",
      "Epoch 703/1000\n",
      "276/276 - 69s - loss: 0.0672 - accuracy: 0.9935\n",
      "Epoch 704/1000\n",
      "276/276 - 69s - loss: 0.0532 - accuracy: 0.9961\n",
      "Epoch 705/1000\n",
      "276/276 - 69s - loss: 0.0449 - accuracy: 0.9973\n",
      "Epoch 706/1000\n",
      "276/276 - 69s - loss: 0.0378 - accuracy: 0.9981\n",
      "Epoch 707/1000\n",
      "276/276 - 69s - loss: 0.0336 - accuracy: 0.9984\n",
      "Epoch 708/1000\n",
      "276/276 - 69s - loss: 0.0298 - accuracy: 0.9988\n",
      "Epoch 709/1000\n",
      "276/276 - 69s - loss: 0.0290 - accuracy: 0.9989\n",
      "Epoch 710/1000\n",
      "276/276 - 68s - loss: 0.0341 - accuracy: 0.9980\n",
      "Epoch 711/1000\n",
      "276/276 - 68s - loss: 0.0815 - accuracy: 0.9873\n",
      "Epoch 712/1000\n",
      "276/276 - 68s - loss: 0.1831 - accuracy: 0.9566\n",
      "Epoch 713/1000\n",
      "276/276 - 68s - loss: 0.1744 - accuracy: 0.9602\n",
      "Epoch 714/1000\n",
      "276/276 - 68s - loss: 0.1321 - accuracy: 0.9750\n",
      "Epoch 715/1000\n",
      "276/276 - 68s - loss: 0.0962 - accuracy: 0.9849\n",
      "Epoch 716/1000\n",
      "276/276 - 68s - loss: 0.0714 - accuracy: 0.9920\n",
      "Epoch 717/1000\n",
      "276/276 - 68s - loss: 0.0547 - accuracy: 0.9951\n",
      "Epoch 718/1000\n",
      "276/276 - 68s - loss: 0.0443 - accuracy: 0.9972\n",
      "Epoch 719/1000\n",
      "276/276 - 68s - loss: 0.0373 - accuracy: 0.9980\n",
      "Epoch 720/1000\n",
      "276/276 - 68s - loss: 0.0332 - accuracy: 0.9984\n",
      "Epoch 721/1000\n",
      "276/276 - 68s - loss: 0.0307 - accuracy: 0.9986\n",
      "Epoch 722/1000\n",
      "276/276 - 68s - loss: 0.0293 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00722: ReduceLROnPlateau reducing learning rate to 0.00040045162313617766.\n",
      "Epoch 723/1000\n",
      "276/276 - 68s - loss: 0.0245 - accuracy: 0.9991\n",
      "Epoch 724/1000\n",
      "276/276 - 68s - loss: 0.0199 - accuracy: 0.9995\n",
      "Epoch 725/1000\n",
      "276/276 - 68s - loss: 0.0165 - accuracy: 0.9997\n",
      "Epoch 726/1000\n",
      "276/276 - 68s - loss: 0.0141 - accuracy: 0.9998\n",
      "Epoch 727/1000\n",
      "276/276 - 68s - loss: 0.0131 - accuracy: 0.9998\n",
      "Epoch 728/1000\n",
      "276/276 - 68s - loss: 0.0126 - accuracy: 0.9998\n",
      "Epoch 729/1000\n",
      "276/276 - 68s - loss: 0.0147 - accuracy: 0.9997\n",
      "Epoch 730/1000\n",
      "276/276 - 68s - loss: 0.0526 - accuracy: 0.9919\n",
      "Epoch 731/1000\n",
      "276/276 - 68s - loss: 0.1485 - accuracy: 0.9654\n",
      "Epoch 732/1000\n",
      "276/276 - 68s - loss: 0.1066 - accuracy: 0.9793\n",
      "Epoch 733/1000\n",
      "276/276 - 68s - loss: 0.0647 - accuracy: 0.9919\n",
      "Epoch 734/1000\n",
      "276/276 - 68s - loss: 0.0418 - accuracy: 0.9970\n",
      "Epoch 735/1000\n",
      "276/276 - 68s - loss: 0.0287 - accuracy: 0.9990\n",
      "Epoch 736/1000\n",
      "276/276 - 68s - loss: 0.0218 - accuracy: 0.9995\n",
      "Epoch 737/1000\n",
      "276/276 - 68s - loss: 0.0167 - accuracy: 0.9998\n",
      "Epoch 738/1000\n",
      "276/276 - 68s - loss: 0.0135 - accuracy: 0.9999\n",
      "Epoch 739/1000\n",
      "276/276 - 68s - loss: 0.0113 - accuracy: 0.9999\n",
      "Epoch 740/1000\n",
      "276/276 - 68s - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "276/276 - 68s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "276/276 - 68s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "276/276 - 68s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "276/276 - 68s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "276/276 - 68s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "276/276 - 68s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "276/276 - 68s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "276/276 - 68s - loss: 0.2181 - accuracy: 0.9406\n",
      "Epoch 749/1000\n",
      "276/276 - 68s - loss: 0.1716 - accuracy: 0.9578\n",
      "Epoch 750/1000\n",
      "276/276 - 68s - loss: 0.0935 - accuracy: 0.9830\n",
      "Epoch 751/1000\n",
      "276/276 - 68s - loss: 0.0552 - accuracy: 0.9939\n",
      "Epoch 752/1000\n",
      "276/276 - 68s - loss: 0.0347 - accuracy: 0.9979\n",
      "Epoch 753/1000\n",
      "276/276 - 68s - loss: 0.0232 - accuracy: 0.9994\n",
      "Epoch 754/1000\n",
      "276/276 - 68s - loss: 0.0168 - accuracy: 0.9998\n",
      "Epoch 755/1000\n",
      "276/276 - 68s - loss: 0.0136 - accuracy: 0.9999\n",
      "Epoch 756/1000\n",
      "276/276 - 68s - loss: 0.0116 - accuracy: 0.9999\n",
      "Epoch 757/1000\n",
      "276/276 - 68s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "276/276 - 68s - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "276/276 - 68s - loss: 0.0077 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00759: ReduceLROnPlateau reducing learning rate to 0.00030033871735213324.\n",
      "Epoch 760/1000\n",
      "276/276 - 68s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "276/276 - 69s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "276/276 - 70s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "276/276 - 70s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "276/276 - 70s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "276/276 - 71s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "276/276 - 71s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "276/276 - 71s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "276/276 - 71s - loss: 0.0839 - accuracy: 0.9798\n",
      "Epoch 769/1000\n",
      "276/276 - 71s - loss: 0.1247 - accuracy: 0.9714\n",
      "Epoch 770/1000\n",
      "276/276 - 71s - loss: 0.0651 - accuracy: 0.9894\n",
      "Epoch 771/1000\n",
      "276/276 - 70s - loss: 0.0343 - accuracy: 0.9976\n",
      "Epoch 772/1000\n",
      "276/276 - 70s - loss: 0.0217 - accuracy: 0.9993\n",
      "Epoch 773/1000\n",
      "276/276 - 71s - loss: 0.0148 - accuracy: 0.9998\n",
      "Epoch 774/1000\n",
      "276/276 - 71s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "276/276 - 71s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "276/276 - 70s - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "276/276 - 70s - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "276/276 - 70s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "276/276 - 70s - loss: 0.0060 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00779: ReduceLROnPlateau reducing learning rate to 0.00022525404347106814.\n",
      "Epoch 780/1000\n",
      "276/276 - 70s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "276/276 - 70s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "276/276 - 70s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "276/276 - 70s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "276/276 - 70s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "276/276 - 70s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "276/276 - 70s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "276/276 - 70s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "276/276 - 69s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "276/276 - 69s - loss: 0.0333 - accuracy: 0.9937\n",
      "Epoch 790/1000\n",
      "276/276 - 69s - loss: 0.0778 - accuracy: 0.9844\n",
      "Epoch 791/1000\n",
      "276/276 - 69s - loss: 0.0363 - accuracy: 0.9960\n",
      "Epoch 792/1000\n",
      "276/276 - 69s - loss: 0.0190 - accuracy: 0.9994\n",
      "Epoch 793/1000\n",
      "276/276 - 69s - loss: 0.0120 - accuracy: 0.9999\n",
      "Epoch 794/1000\n",
      "276/276 - 69s - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "276/276 - 69s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "276/276 - 70s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "276/276 - 70s - loss: 0.0061 - accuracy: 0.9999\n",
      "Epoch 798/1000\n",
      "276/276 - 70s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "276/276 - 71s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "276/276 - 71s - loss: 0.0044 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00800: ReduceLROnPlateau reducing learning rate to 0.0001689405326033011.\n",
      "Epoch 801/1000\n",
      "276/276 - 71s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "276/276 - 71s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "276/276 - 70s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "276/276 - 70s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "276/276 - 70s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "276/276 - 70s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "276/276 - 71s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "276/276 - 71s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "276/276 - 71s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "276/276 - 70s - loss: 0.0072 - accuracy: 0.9995\n",
      "Epoch 811/1000\n",
      "276/276 - 70s - loss: 0.0413 - accuracy: 0.9936\n",
      "Epoch 812/1000\n",
      "276/276 - 70s - loss: 0.0226 - accuracy: 0.9978\n",
      "Epoch 813/1000\n",
      "276/276 - 70s - loss: 0.0115 - accuracy: 0.9997\n",
      "Epoch 814/1000\n",
      "276/276 - 70s - loss: 0.0071 - accuracy: 0.9999\n",
      "Epoch 815/1000\n",
      "276/276 - 70s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "276/276 - 70s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "276/276 - 70s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "276/276 - 70s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "276/276 - 70s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "276/276 - 70s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "276/276 - 70s - loss: 0.0030 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00821: ReduceLROnPlateau reducing learning rate to 0.00012670539945247583.\n",
      "Epoch 822/1000\n",
      "276/276 - 69s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "276/276 - 69s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "276/276 - 69s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "276/276 - 69s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "276/276 - 69s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "276/276 - 69s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "276/276 - 69s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "276/276 - 69s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "276/276 - 68s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "276/276 - 68s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "276/276 - 68s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "276/276 - 68s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "276/276 - 68s - loss: 0.0125 - accuracy: 0.9988\n",
      "Epoch 835/1000\n",
      "276/276 - 68s - loss: 0.0128 - accuracy: 0.9990\n",
      "Epoch 836/1000\n",
      "276/276 - 68s - loss: 0.0064 - accuracy: 0.9999\n",
      "Epoch 837/1000\n",
      "276/276 - 68s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "276/276 - 68s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "276/276 - 68s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "276/276 - 68s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "276/276 - 68s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "276/276 - 68s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "276/276 - 68s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "276/276 - 68s - loss: 0.0018 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00844: ReduceLROnPlateau reducing learning rate to 9.502905231784098e-05.\n",
      "Epoch 845/1000\n",
      "276/276 - 68s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "276/276 - 68s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "276/276 - 68s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "276/276 - 68s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "276/276 - 68s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "276/276 - 68s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "276/276 - 68s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "276/276 - 68s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "276/276 - 68s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "276/276 - 68s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "276/276 - 68s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "276/276 - 68s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "276/276 - 68s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "276/276 - 68s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "276/276 - 68s - loss: 0.0037 - accuracy: 0.9998\n",
      "Epoch 860/1000\n",
      "276/276 - 68s - loss: 0.0071 - accuracy: 0.9995\n",
      "Epoch 861/1000\n",
      "276/276 - 68s - loss: 0.0035 - accuracy: 0.9999\n",
      "Epoch 862/1000\n",
      "276/276 - 68s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "276/276 - 68s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "276/276 - 68s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "276/276 - 68s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "276/276 - 68s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "276/276 - 68s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "276/276 - 68s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "276/276 - 68s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "276/276 - 68s - loss: 0.0010 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00870: ReduceLROnPlateau reducing learning rate to 7.127179196686484e-05.\n",
      "Epoch 871/1000\n",
      "276/276 - 68s - loss: 9.4819e-04 - accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "276/276 - 68s - loss: 9.1254e-04 - accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "276/276 - 68s - loss: 8.8043e-04 - accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "276/276 - 68s - loss: 8.4932e-04 - accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "276/276 - 68s - loss: 8.1923e-04 - accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "276/276 - 68s - loss: 7.9057e-04 - accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "276/276 - 68s - loss: 7.6194e-04 - accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "276/276 - 68s - loss: 7.5060e-04 - accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "276/276 - 68s - loss: 7.1899e-04 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "276/276 - 68s - loss: 6.9174e-04 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "276/276 - 68s - loss: 7.4212e-04 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "276/276 - 68s - loss: 7.2363e-04 - accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "276/276 - 68s - loss: 8.2139e-04 - accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "276/276 - 68s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "276/276 - 68s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "276/276 - 68s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "276/276 - 68s - loss: 9.8320e-04 - accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "276/276 - 69s - loss: 8.2033e-04 - accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "276/276 - 70s - loss: 6.8423e-04 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "276/276 - 70s - loss: 6.3188e-04 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "276/276 - 70s - loss: 5.9285e-04 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "276/276 - 71s - loss: 5.6430e-04 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "276/276 - 71s - loss: 5.4118e-04 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "276/276 - 71s - loss: 5.1933e-04 - accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "276/276 - 71s - loss: 5.0017e-04 - accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "276/276 - 71s - loss: 4.8210e-04 - accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "276/276 - 70s - loss: 4.6543e-04 - accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "276/276 - 70s - loss: 4.4987e-04 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "276/276 - 70s - loss: 4.3409e-04 - accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "276/276 - 70s - loss: 4.2059e-04 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "276/276 - 70s - loss: 4.0669e-04 - accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "276/276 - 71s - loss: 3.9573e-04 - accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "276/276 - 70s - loss: 4.1072e-04 - accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "276/276 - 70s - loss: 8.2256e-04 - accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "276/276 - 70s - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 906/1000\n",
      "276/276 - 70s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "276/276 - 70s - loss: 8.7202e-04 - accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "276/276 - 70s - loss: 6.1601e-04 - accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "276/276 - 70s - loss: 5.0699e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00909: ReduceLROnPlateau reducing learning rate to 5.3453841246664524e-05.\n",
      "Epoch 910/1000\n",
      "276/276 - 70s - loss: 4.6044e-04 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "276/276 - 70s - loss: 4.3772e-04 - accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "276/276 - 70s - loss: 4.1947e-04 - accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "276/276 - 70s - loss: 4.0380e-04 - accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "276/276 - 70s - loss: 3.8952e-04 - accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "276/276 - 69s - loss: 3.7629e-04 - accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "276/276 - 69s - loss: 3.6419e-04 - accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "276/276 - 69s - loss: 3.5228e-04 - accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "276/276 - 69s - loss: 3.4170e-04 - accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "276/276 - 69s - loss: 3.3111e-04 - accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "276/276 - 69s - loss: 3.2151e-04 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "276/276 - 69s - loss: 3.1169e-04 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "276/276 - 69s - loss: 3.0261e-04 - accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "276/276 - 69s - loss: 2.9454e-04 - accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "276/276 - 68s - loss: 2.8638e-04 - accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "276/276 - 68s - loss: 2.7810e-04 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "276/276 - 68s - loss: 2.7008e-04 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "276/276 - 68s - loss: 2.6327e-04 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "276/276 - 68s - loss: 2.6232e-04 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "276/276 - 68s - loss: 2.9570e-04 - accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "276/276 - 68s - loss: 7.2812e-04 - accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "276/276 - 68s - loss: 8.8766e-04 - accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "276/276 - 68s - loss: 4.8725e-04 - accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "276/276 - 68s - loss: 3.5722e-04 - accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "276/276 - 68s - loss: 3.0754e-04 - accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "276/276 - 68s - loss: 2.8605e-04 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "276/276 - 68s - loss: 2.7502e-04 - accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "276/276 - 68s - loss: 2.6318e-04 - accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "276/276 - 68s - loss: 2.5530e-04 - accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "276/276 - 68s - loss: 2.4866e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00939: ReduceLROnPlateau reducing learning rate to 4.009038093499839e-05.\n",
      "Epoch 940/1000\n",
      "276/276 - 68s - loss: 2.6204e-04 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "276/276 - 68s - loss: 2.2789e-04 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "276/276 - 68s - loss: 2.2050e-04 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "276/276 - 68s - loss: 2.1467e-04 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "276/276 - 68s - loss: 2.0937e-04 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "276/276 - 68s - loss: 2.0414e-04 - accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "276/276 - 68s - loss: 1.9939e-04 - accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "276/276 - 68s - loss: 1.9544e-04 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "276/276 - 68s - loss: 1.9008e-04 - accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "276/276 - 68s - loss: 1.8554e-04 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "276/276 - 68s - loss: 1.8114e-04 - accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "276/276 - 68s - loss: 1.7689e-04 - accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "276/276 - 68s - loss: 1.7327e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00952: ReduceLROnPlateau reducing learning rate to 3.0067785701248795e-05.\n",
      "Epoch 953/1000\n",
      "276/276 - 68s - loss: 1.6748e-04 - accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "276/276 - 68s - loss: 1.6283e-04 - accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "276/276 - 68s - loss: 1.5894e-04 - accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "276/276 - 68s - loss: 1.5547e-04 - accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "276/276 - 68s - loss: 1.5289e-04 - accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "276/276 - 68s - loss: 1.5092e-04 - accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "276/276 - 68s - loss: 1.4758e-04 - accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "276/276 - 68s - loss: 1.4588e-04 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "276/276 - 68s - loss: 1.6460e-04 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "276/276 - 68s - loss: 1.8103e-04 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "276/276 - 68s - loss: 2.6648e-04 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "276/276 - 68s - loss: 1.9088e-04 - accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "276/276 - 68s - loss: 1.6129e-04 - accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "276/276 - 68s - loss: 1.4077e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00966: ReduceLROnPlateau reducing learning rate to 2.2550839275936596e-05.\n",
      "Epoch 967/1000\n",
      "276/276 - 68s - loss: 1.3406e-04 - accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "276/276 - 68s - loss: 1.3089e-04 - accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "276/276 - 68s - loss: 1.2833e-04 - accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "276/276 - 68s - loss: 1.2607e-04 - accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "276/276 - 68s - loss: 1.2400e-04 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "276/276 - 68s - loss: 1.2202e-04 - accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "276/276 - 68s - loss: 1.2013e-04 - accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "276/276 - 68s - loss: 1.1828e-04 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "276/276 - 68s - loss: 1.1650e-04 - accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "276/276 - 68s - loss: 1.1474e-04 - accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "276/276 - 68s - loss: 1.1296e-04 - accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "276/276 - 68s - loss: 1.1128e-04 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "276/276 - 68s - loss: 1.0960e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00979: ReduceLROnPlateau reducing learning rate to 1.6913129456952447e-05.\n",
      "Epoch 980/1000\n",
      "276/276 - 68s - loss: 1.0720e-04 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "276/276 - 68s - loss: 1.0564e-04 - accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "276/276 - 68s - loss: 1.0417e-04 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "276/276 - 68s - loss: 1.0283e-04 - accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "276/276 - 68s - loss: 1.0145e-04 - accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "276/276 - 68s - loss: 1.0010e-04 - accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "276/276 - 68s - loss: 9.8926e-05 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "276/276 - 68s - loss: 9.7622e-05 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "276/276 - 68s - loss: 9.6322e-05 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "276/276 - 68s - loss: 9.5332e-05 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "276/276 - 68s - loss: 9.3751e-05 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "276/276 - 68s - loss: 9.2254e-05 - accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "276/276 - 68s - loss: 9.0873e-05 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00992: ReduceLROnPlateau reducing learning rate to 1.2684846751653822e-05.\n",
      "Epoch 993/1000\n",
      "276/276 - 68s - loss: 8.8955e-05 - accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "276/276 - 68s - loss: 8.7649e-05 - accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "276/276 - 68s - loss: 8.6573e-05 - accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "276/276 - 68s - loss: 8.5532e-05 - accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "276/276 - 68s - loss: 8.4604e-05 - accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "276/276 - 68s - loss: 8.3700e-05 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "276/276 - 68s - loss: 8.2805e-05 - accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "276/276 - 68s - loss: 8.1813e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# la callback lavora sul loss e non sull'accuracy, come in altri casi,\n",
    "# perché l'accuracy ci dà \"1\" quando l'output con probabilità più alta\n",
    "# coincide con il valore vero, indipendentemente da quanto valgono gli\n",
    "# altri output. Il loss tiene in considerazione tutti gli output e\n",
    "# quando stagna questo indicatore potrebbe aver senso diminuire il\n",
    "# learning rate per far proseguire l'addestramento (considerando\n",
    "# l'accuracy, il learning rate diminuirebbe nel momento in cui, di\n",
    "# epoca in epoca, il modello fornisse lo stesso numero di output\n",
    "# uguali ai valori desiderati, mentre invece potrebbe comunque\n",
    "# stare ancora migliorando le sue performance, considerando appunto\n",
    "# il loss)\n",
    "history = model.fit(\n",
    "    examples,\n",
    "    labels,\n",
    "    epochs=1000,\n",
    "    batch_size=512,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(\n",
    "            patience=13,\n",
    "            factor=0.75,\n",
    "            monitor='loss',\n",
    "            mode='min',\n",
    "            min_lr=1e-5,\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            patience=42,\n",
    "            monitor='loss',\n",
    "            mode='min',\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# backup addestramento\n",
    "\n",
    "model.save_weights('weights/words_generation')\n",
    "pickle.dump(history.history, open('weights/history.bck', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recupero pesi e log di addestramento\n",
    "model.load_weights('weights/words_generation')\n",
    "history = pickle.load(open('weights/history.bck', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnZUlEQVR4nO3dd3wVVf7/8deHBEEInSAKKqAsiKCwRhSxgCh2WQs2UEBdwIZtF8vX/cnaXXdXxV1R7AqC3bUBCqLYMSAWBFZXQYKFiIWi1Hx+f5wbiRggCXcyt7yfj8d95N65c+98hoE3J2dmzjF3R0REMk+NuAsQEZFoKOBFRDKUAl5EJEMp4EVEMpQCXkQkQyngRUQylAJeMpaZTTCzAclet5I19DCzomR/r0hF5MZdgEhZZra8zMs6wCpgXeL1EHcfW9HvcvfDolhXJF0o4CWluHte6XMzmw+c6e6TN1zPzHLdfW111iaSbtRFI2mhtKvDzC4xs6+B+8yskZk9Z2bFZvZ94nnLMp95xczOTDwfaGavm9nfE+t+bmaHVXHd1mY2zcyWmdlkM/u3mY2p4H7sktjWD2Y228yOLvPe4Wb2ceJ7F5nZnxLLmyb27Qcz+87MXjMz/duVzdJfEkknzYHGwI7AYMLf3/sSr3cAfgb+tYnP7wXMA5oCfwPuMTOrwroPA9OBJsAI4NSKFG9mNYFngReBZsB5wFgza5dY5R5CN1Q9oCPwcmL5xUARkA9sA1wOaIwR2SwFvKSTEuBKd1/l7j+7+xJ3f8Ldf3L3ZcC1wAGb+PwCd7/L3dcBDwDbEgKzwuua2Q7AnsD/c/fV7v468EwF698byANuSHz2ZeA54OTE+2uADmZW392/d/eZZZZvC+zo7mvc/TXXIFJSAQp4SSfF7r6y9IWZ1TGzO81sgZktBaYBDc0sZyOf/7r0ibv/lHiaV8l1twO+K7MMYGEF698OWOjuJWWWLQBaJJ4fBxwOLDCzV82sW2L5TcCnwItm9pmZXVrB7UmWU8BLOtmw1Xox0A7Yy93rA/snlm+s2yUZvgIam1mdMsu2r+BnvwS236D/fAdgEYC7v+vufQjdN08DjyaWL3P3i929DXA0cJGZ9dqy3ZBsoICXdFaP0O/+g5k1Bq6MeoPuvgAoBEaY2VaJVvZRFfz4O8BPwHAzq2lmPRKfHZ/4rn5m1sDd1wBLCV1SmNmRZrZz4hzAj4TLRkvK3YJIGQp4SWe3AFsD3wJvAxOrabv9gG7AEuAa4BHC9fqb5O6rCYF+GKHm24HT3H1uYpVTgfmJ7qahie0AtAUmA8uBt4Db3X1q0vZGMpbpXI3IljGzR4C57h75bxAilaEWvEglmdmeZraTmdUws0OBPoQ+c5GUojtZRSqvOfAk4Tr4IuAsd38v3pJEfktdNCIiGUpdNCIiGSqlumiaNm3qrVq1irsMEZG0MWPGjG/dPb+891Iq4Fu1akVhYWHcZYiIpA0zW7Cx99RFIyKSoRTwIiIZSgEvIpKhUqoPXkRSy5o1aygqKmLlypWbX1kiVbt2bVq2bEnNmjUr/BkFvIhsVFFREfXq1aNVq1ZsfG4UiZq7s2TJEoqKimjdunWFP6cuGhHZqJUrV9KkSROFe8zMjCZNmlT6NykFvIhsksI9NVTlOEQW8GbWzsxmlXksNbMLkr2dtWvh+uth0qRkf7OISHqLLODdfZ67d3b3zsAehIkOnkr2dnJy4Kab4Kmkf7OIxG3JkiV07tyZzp0707x5c1q0aPHL69WrV2/ys4WFhQwbNmyz29hnn32SUusrr7zCkUcemZTvSpbqOsnaC/hfYjacpDKDdu1g3rxkf7OIxK1JkybMmjULgBEjRpCXl8ef/vSnX95fu3Ytubnlx1hBQQEFBQWb3cabb76ZlFpTUXX1wZ8EjCvvDTMbbGaFZlZYXFxcpS9v3x7mzt38ehV16aVw443J+z4RSZ6BAwcydOhQ9tprL4YPH8706dPp1q0bXbp0YZ999mFeorVXtkU9YsQITj/9dHr06EGbNm0YOXLkL9+Xl5f3y/o9evTg+OOPp3379vTr14/S0XZfeOEF2rdvzx577MGwYcMq1VIfN24cnTp1omPHjlxyySUArFu3joEDB9KxY0c6derEzTffDMDIkSPp0KEDu+22GyeddNIW/1lF3oI3s60IEwVfVt777j4aGA1QUFBQpbGL27WD+++HKVNg222hbl3Yeuvw3po1kJsLJSVQuzbk5cHmLiMtDffzzoM6dTa9rki2uOACSDSmk6ZzZ7jllsp/rqioiDfffJOcnByWLl3Ka6+9Rm5uLpMnT+byyy/niSee+M1n5s6dy9SpU1m2bBnt2rXjrLPO+s015e+99x6zZ89mu+22o3v37rzxxhsUFBQwZMgQpk2bRuvWrTn55JMrXOeXX37JJZdcwowZM2jUqBG9e/fm6aefZvvtt2fRokV89NFHAPzwww8A3HDDDXz++efUqlXrl2Vbojpa8IcBM939m6g2cOihIdAPOgh23RVatYJttgmPli2heXPYbjto3Bg29xtbSZmpjJ99FmbPjqpqEamqvn37kpOTA8CPP/5I37596dixIxdeeCGzN/KP9ogjjqBWrVo0bdqUZs2a8c03v42krl270rJlS2rUqEHnzp2ZP38+c+fOpU2bNr9cf16ZgH/33Xfp0aMH+fn55Obm0q9fP6ZNm0abNm347LPPOO+885g4cSL169cHYLfddqNfv36MGTNmo11PlVEdffAns5HumWTp3BkWLYI334Tly+Gnn2DFitA/X7MmrFwZWvEvvwxPPBFOytavH1r3a9fCySeH/wwAvv9+/feW/oa0YoVa8iJVaWlHpW7dur88/8tf/kLPnj156qmnmD9/Pj169Cj3M7Vq1frleU5ODmvXrq3SOsnQqFEj3n//fSZNmsQdd9zBo48+yr333svzzz/PtGnTePbZZ7n22mv58MMPtyjoIw14M6sLHAwMiXI7AI0awRFHbHqd/fYLrfLhw3+9fNYsuOIKWLcOZs787edmz4Y990xaqSKSRD/++CMtWrQA4P7770/697dr147PPvuM+fPn06pVKx555JEKf7Zr164MGzaMb7/9lkaNGjFu3DjOO+88vv32W7baaiuOO+442rVrR//+/SkpKWHhwoX07NmTfffdl/Hjx7N8+XIaNmxY5dojDXh3X0GYtzIldOoEX30VWvk5OaFV37cvPPBAeJTVsSMkusc48UTo0wdOOSWc0K1Xr/prF5HyDR8+nAEDBnDNNddwxOZaeVWw9dZbc/vtt3PooYdSt25d9txEa2/KlCm0bNnyl9ePPfYYN9xwAz179sTdOeKII+jTpw/vv/8+gwYNoiTRJ3z99dezbt06+vfvz48//oi7M2zYsC0Kd0ixOVkLCgq8uif8WLwYJkyAGjVC6K9eHU7arlgBZ54JCza4sLNtW5g2LfTri2S6OXPmsMsuu8RdRuyWL19OXl4e7s4555xD27ZtufDCC6u9jvKOh5nNcPdyzy5m/WBjzZrBgAHlvzd/fvj51lvw3nswejS8/z7svTdcdBGccUa4YkdEMttdd93FAw88wOrVq+nSpQtDhkTe65wUWd+Cr6zJk+Hii+GDD8JVOxMnhpa/SCZSCz61VLYFr8HGKumgg0Jr/p//DGF/0UVxVyQSrVRqBGazqhwHBXwV1KgBF14IZ58Nt90GL74Yd0Ui0ahduzZLlixRyMesdDz42rVrV+pz6qLZAkuXQrdu8N138PHH4VJNkUyiGZ1Sx8ZmdNJJ1ojUrw8PPghdu4a7ad98U/3xkllq1qxZqRmEJLWoi2YL7bEHjBwJ06fDPffEXY2IyHoK+CQ4+2w44IAwGFMGjzwqImlGAZ8EZvDoo2Fgs6OOgqKiuCsSEVHAJ02zZvD887BqVRjSYDOTzYiIRE4Bn0Rt24a7XV97DYYOhRS6QElEspCuokmyU04J0wdedRW0aAFXXx13RSKSrRTwERgxAr78Eq65Jowzf+65cVckItlIAR8BMxg1KoxUOWxYCPm+feOuSkSyjfrgI5KbC+PHQ/fu0L8/TJ0ad0Uikm0U8BHaemt45plw8rVPnzBImYhIdVHAR6xRozCkcMOGcNhh8L//xV2RiGQLBXw1aNkSJk0Kk3zvv//6qQBFRKIUacCbWUMze9zM5prZHDPrFuX2Utkuu8Arr4Tn++0Hr78eazkikgWibsHfCkx09/bA7sCciLeX0jp1gjfeCHe9HnwwPPts3BWJSCaLLODNrAGwP3APgLuvdvcfotpeumjVKrTeO3WCY46Be++NuyIRyVRRtuBbA8XAfWb2npndbWa/maLazAabWaGZFRYXF0dYTurIz4eXX4ZevcLE3VddpWENRCT5ogz4XOD3wCh37wKsAC7dcCV3H+3uBe5ekJ+fH2E5qSUvL3TRDBgAV14ZhhpesybuqkQkk0R5J2sRUOTu7yReP045AZ/NttoqdNE0bAi33gpffQVjx8IGM3KJiFRJZAHv7l+b2UIza+fu84BewMdRbS9d1agBt9wCO+wAF18MS5bAY49B48ZxVyYi6S7qq2jOA8aa2QdAZ+C6iLeXti66KMzv+vrrsPfe8N//xl2RiKS7SAPe3Wcl+td3c/c/uPv3UW4v3Z16KkyZAt9/H0L+5ZfjrkhE0pnuZE0x++4bJvDebjs45BC48864KxKRdKWAT0GtW4fJuw8+OMwMdeWVuoxSRCpPAZ+i6tcPI1Gefnq4Tv6CC6CkJO6qRCSdaMKPFJabC3ffDQ0awM03h6kAx46FJk3irkxE0oFa8CnODP7xD7jjjjBpSPfuGnJYRCpGAZ8GzGDIEJg8GYqLYa+9YNq0uKsSkVSngE8j++0H77wDTZvCQQfBAw/EXZGIpDIFfJrZeWd4660wccjAgXDZZTr5KiLlU8CnoUaNYMKE0G1zww3Qty+sWBF3VSKSahTwaapmTRg1Klxd8/TT0K0bLFgQd1UikkoU8GnMLFwfP2ECfPFFOPk6eXLcVYlIqlDAZ4DevcOdr3XqhLtfR46MuyIRSQUK+AzRoQN8+CH84Q9w/vka3kBEFPAZpW7dMJZ86fAG554L69bFXZWIxEVDFWSY0uENmjSBm26Czz6DRx+FevXirkxEqpta8BnIDP72tzC8wUsvQZ8+sHJl3FWJSHVTwGewIUPg/vvDGDannKI+eZFso4DPcP37w7XXwlNPwdtvx12NiFQnBXwWOOecMLn3hAlxVyIi1SnSgDez+Wb2oZnNMrPCKLclG9egAeyxh+Z4Fck21dGC7+nund29oBq2JRtx4IFhrleNWSOSPdRFkyV69oQ1a+CNN+KuRESqS9QB78CLZjbDzAaXt4KZDTazQjMrLC4ujric7NW9e7hGfurUuCsRkeoSdcDv6+6/Bw4DzjGz/Tdcwd1Hu3uBuxfk5+dHXE72ysuDrl0V8CLZJNKAd/dFiZ+LgaeArlFuTzatZ08oLISlS+OuRESqQ2QBb2Z1zaxe6XOgN/BRVNuTzTvkkDA2zbPPxl2JiFSHKFvw2wCvm9n7wHTgeXefGOH2ZDP23Rd22gnuvTfuSkSkOkQ22Ji7fwbsHtX3S+WZwaBBcMUV8Pnn0Lp13BWJSJR0mWSWOe20EPT33x93JSISNQV8ltl++zAD1H33aax4kUyngM9Cp58OCxdq6AKRTKeAz0J9+kCjRuqmEcl0CvgsVKsWHHtsuFxSE4GIZC4FfJbq2xeWLYNJk+KuRESiooDPUgceCI0bh0m6RSQzKeCzVM2aoRX/xBPw7bdxVyMiUVDAZ7Fzzw198A8/HHclIhIFBXwW69gRfv/7MHSBJuQWyTwK+Cz3xz/C+++H2Z5EJLMo4LNcv35hrPg77oi7EhFJNgV8lqtXL4T8+PHw/fdxVyMiyaSAF4YMCSdbH3ww7kpEJJkU8EKXLrDXXqGbRidbRTKHAl4AGDoU5s6F116LuxIRSRYFvABwwgnQsCGMGhV3JSKSLAp4AaBOHTj1VHjySfjuu7irEZFkUMDLL04/HVavhnHj4q5ERJIh8oA3sxwze8/Mnot6W7JlOncOj/vui7sSEUmG6mjBnw/MqYbtSBIMGgQzZsAHH8RdiYhsqUgD3sxaAkcAd0e5HUmefv1gq63UihfJBFG34G8BhgMlG1vBzAabWaGZFRYXF0dcjmxOkyZw9NEwZkzojxeR9BVZwJvZkcBid5+xqfXcfbS7F7h7QX5+flTlSCUMGhTGiH9OZ01E0lqULfjuwNFmNh8YDxxoZmMi3J4kSe/esN12YRhhEUlfkQW8u1/m7i3dvRVwEvCyu/ePanuSPLm5MHAgTJgAX3wRdzUiUlW6Dl7KNXhwGJfmrrvirkREqqpaAt7dX3H3I6tjW5IcO+4IRxwBd98Na9bEXY2IVIVa8LJRZ50FX38NTz8ddyUiUhUVCngzO9/M6ltwj5nNNLPeURcn8TrkEGjVCkaPjrsSEamKirbgT3f3pUBvoBFwKnBDZFVJSsjJgdNOgylTYNGiuKsRkcqqaMBb4ufhwEPuPrvMMslg/fuHk61jx8ZdiYhUVkUDfoaZvUgI+ElmVo9N3J0qmaNtW9hnn3BNvGZ7EkkvFQ34M4BLgT3d/SegJjAosqokpZx5JsybB2+8EXclIlIZFQ34bsA8d//BzPoDVwA/RleWpJITToB69XSyVSTdVDTgRwE/mdnuwMXA/4AHI6tKUkrduqEv/tFHNduTSDqpaMCvdXcH+gD/cvd/A/WiK0tSzZAhsGpVGGVSRNJDRQN+mZldRrg88nkzq0Hoh5cssfvuYbanhx+OuxIRqaiKBvyJwCrC9fBfAy2BmyKrSlLSKafAO+/Ap5/GXYmIVESFAj4R6mOBBolx3le6u/rgs8wpp0DNmnDrrXFXIiIVUdGhCk4ApgN9gROAd8zs+CgLk9TTogX07Ru6aTTbk0jqq2gXzf8RroEf4O6nAV2Bv0RXlqSqfv3ClTQTJ8ZdiYhsTkUDvoa7Ly7zekklPisZ5OCDIT8fHnoo7kpEZHMqGtITzWySmQ00s4HA88AL0ZUlqapmzdCK/89/oKgo7mpEZFMqepL1z8BoYLfEY7S7XxJlYZK6zj8fSkp0slUk1Zmn0AhSBQUFXlhYGHcZUgGnnALPPRda8fXrx12NSPYysxnuXlDee5tswZvZMjNbWs5jmZktjaZcSQfnnw/LlsG4cXFXIiIbs8mAd/d67l6/nEc9d99ku83MapvZdDN738xmm9lfk1u6xKlrV9htNw1AJpLKorwSZhVwoLvvDnQGDjWzvSPcnlQjMxg8GGbOBPWqiaSmyALeg+WJlzUTj9Tp8Jct1r8/1KkDt98edyUiUp5Ir2U3sxwzmwUsBl5y93fKWWewmRWaWWFxcXGU5UiSNWgAAweG6fy+/DLuakRkQ5EGvLuvc/fOhMHJuppZx3LWGe3uBe5ekJ+fH2U5EoGLLoI1a+Bf/4q7EhHZULXcjeruPwBTgUOrY3tSfXbaCY45BkaNguXLN7++iFSfyALezPLNrGHi+dbAwcDcqLYn8fnTn+CHH0LIi0jqiLIFvy0w1cw+AN4l9ME/F+H2JCbdukGvXuHO1nXr4q5GREpFeRXNB+7exd13c/eO7n5VVNuS+A0dCosWwUsvxV2JiJTSiJCSFEcdBU2awD/+EXclIlJKAS9JUasWDB8OkyfDu+/GXY2IgAJekujMM6FZM7jyyrgrERFQwEsSNW4MZ58NEybAvHlxVyMiCnhJqrPOgq23hhtuiLsSEVHAS1I1awZ//COMGQMLFsRdjUh2U8BL0v35z2G0yZtuirsSkeymgJeka9kSBgyAu++Gb76JuxqR7KWAl0gMHx4GIbvllrgrEcleCniJRNu2cPzxYZTJoqK4qxHJTgp4icy118Lq1dC3L6TQ3O4iWUMBL5HZeecQ8m+/rbtbReKggJdIDR4cZn4680xYtSruakSyiwJeIlW/PtxxB3z4IYwfH3c1ItlFAS+RO/FE2HXXMNKkxosXqT4KeImcGVx+eWjFP/FE3NWIZA8FvFSLE0+E3/0OLrkEVq6MuxqR7KCAl2qRkxNuepo/H/r3V1eNSHVQwEu1OewwuOKK0E1z221xVyOS+SILeDPb3symmtnHZjbbzM6PaluSPq6+Gg46CK67DpYvj7sakcwWZQt+LXCxu3cA9gbOMbMOEW5P0sTVV0NxMdx8c9yViGS2yALe3b9y95mJ58uAOUCLqLYn6WPvvcM4NddeC3Pnxl2NSOaqlj54M2sFdAHeKee9wWZWaGaFxcXF1VGOpIDbboO6dWHQoDBejYgkX+QBb2Z5wBPABe6+dMP33X20uxe4e0F+fn7U5UiKaN48jDT59tvhGnkRSb5IA97MahLCfay7PxnltiT9nHwynH463HqrumpEohDlVTQG3APMcfd/RrUdSW/XXw916sB55+naeJFki7IF3x04FTjQzGYlHodHuD1JQ82awY03wuTJIexFJHlyo/pid38dsKi+XzLH0KHw6qvw179C797QtWvcFYlkBt3JKilh1CjYbjv4wx/ggw/irkYkMyjgJSU0bAgvvBBGnjzuOFj6m+utRKSyFPCSMnbdFR58ED79NNztKiJbRgEvKaVXr9BN849/wD33xF2NSHpTwEvKGT0a2rcP87g+91zc1YikLwW8pJz8fJg+Pfw86ii46qq4KxJJTwp4SUl5efDww+H5iBHw2muxliOSlhTwkrIOOgi++gpatID994cxY+KuSCS9KOAlpTVvDg89FJ4PGABffBFvPSLpRAEvKa9HD/jkEygpgbZtYfHiuCsSSQ8KeEkLO+8crq5ZvRqOOQaWLYu7IpHUp4CXtPHHP4Z++DffhEMPhc8/j7sikdSmgJe00q8f3H47zJ4dWvKaBExk4xTwknbOOitcQjl3LuywQ7hO3j3uqkRSjwJe0tLhh8Nbb0GnTnDlldC3r0JeZEMKeElbXbqEkN9nH3jiiXAZ5cyZcVclkjoU8JLWcnLgpZfg2GPD9fKHHQYvvxx3VSKpQQEvaa9OndCCnz49dNP06gUPPBB3VSLxU8BLxthzT5g/P0z5N3BgmDxk1Ki4qxKJT2QBb2b3mtliM/soqm2IbKhOHZgyBY4+Orw++2y4++5wF6xItomyBX8/cGiE3y9Srrw8+M9/YOpU6Nw53CC1557h+vkFC+KuTqT6RBbw7j4N+C6q7xfZnB49wlU1118ffp5zDnTsGPrr1aKXbBB7H7yZDTazQjMrLNZtiZJkZnDppWEMmzvvhOXL4fjjw4xRL7wQd3Ui0Yo94N19tLsXuHtBfn5+3OVIhqpZEwYPDpdUHnMMrFgBRxwRHhMmwNKlcVcoknyxB7xIdTroIHjyyTD88F57hVb84YdDgwbwu9/BG2/EXaFI8ijgJSvVqQOvvBJuirrpJjjggBD6++4LPXvCjTfCdzqDJGnOPKIBPMxsHNADaAp8A1zp7vds6jMFBQVeWFgYST0im/PllzBoELz4YnjdsCH83/9Bnz5hohGRVGRmM9y9oNz3ogr4qlDAS9zcw6WUL7wA110HixaF5W3bhv769u2hVSvo3TucwBWJmwJepAq+/RYuvzz0y8+Z89vRKo89NnTlbLMNrFkDjRvHU6dkt00FvPrgRTaiadMwTeDs2bBuHRQWhlDv1Su8/+SToWVfvz40aRJ+/u1voYtn3bqwzrJlYdx6kTgo4EUqwAz22CPcJDV5cgjuOXPgpJPWr7NsGVxyCRxyCOTmhs/Urw+77BLGxCksDNfgT5sW335IdlEXjUiS/PADPP44/Pwz/P3v8MUXYXleXrjBqtTWW4egnzED/vnPcInmzjuH9a+/Hi66CLp1i2UXJA2pD16kmpWUhPliS0qgWbPQV3/zzXDffTB06PqTt5uSnw8nnBBuxGrVCo46CoqK4JproHbtTX/WXSeBs4UCXiQFlIZuURHMmxeCf9o0+P57uOeeMNTxuefC11+H3wQ2pX172H//8NnPP4czzwxX/hx9dHielxf+Y9hnnzBMw1NPQevW4eYuBX9mUcCLpDh3WLs2DKkA4STtXXeFoP755zAq5p13hn783NzQvVMRjRv/+oatkSPhvPOSXr7EaFMBn1vdxYjIb5mtD3cIUxEOHfrrdfbcc/3zkpJwsjcvL5z8nTQJmjcPrfbDDgvv//nP4beFAw8Ml3y+8kqYw1YBnz0U8CJpqEaNcLNVqdIJTrp2Xb/stdd+/Zk99wxdOpI9dJmkSJbYdlv46qu4q5DqpIAXyRLNm4cTuJI9FPAiWaJ583DpZuldtpL51AcvkiW23TacfF28GMaMgVWrwonYWrXirkyioha8SJZo0yb8HDMGhg+Hv/wl3DC1yy7hEk3JPAp4kSxRepnl8OHQqBHcey/stFMYDO3zz+OtTaKhgBfJEo0bh+kJIYyBM2gQjB0bXpcOh/zYY/Dee1XfxvTpsMMO4bp7iZ8CXiSLjB8Pb78NAweG1+3ahZ9z58LUqWHsmx49wt2zpT78EHbdNdwktTkjR8LChZsfakGqhwJeJIvUqxfGoynVsGE4+VpYGIZGAFi6FC6+OAQ1wKuvwscfw9VX//q7/v3vML5N2dFOfve78POzz3677TlzwpDKUn0U8CJZ7oQTQtfM+PFhGIPjjgvj1++7b7jqpnTky5kzfx3m554bBkj7+OP1y9asCT+//PLX21ixAjp0gJNPjnRXZAORBryZHWpm88zsUzO7NMptiUjVXHddmKRkp53ChCX33x/mn/3iC3jmmTBHLcA334RRKUvtuGP4OXny+mWlLfRZs369jdLuneef/+32r702XMmTQuMeZozIAt7McoB/A4cBHYCTzaxDVNsTkaqpUwcmToRPPoEWLcIAZo8/HkL3pJNg3Lgw1k2HDnDqqWE44qeeWj/swW23hXFvvv0WliwJy2bPhgceCNfcr14N//3v+u0VFoY+/tJAv+KKcA5g2rRf34S1cGE4Yfvkk+XXvWDBprt89B9GhMMFm1k3YIS7H5J4fRmAu1+/sc9ouGCR1PHNN+Fa+dKZp9q2DS38Z54J/fQAZ5wRundKX0No2Tdt+ushjc1C4JYdvtgsDH1c2q1Tuqx27bC8bHjXrh1mwqpZMwy0tm5duCs3NzecR9hqq9CdVFIS3lu3Lny+WbPwmZyc8LnybGx8/Mos39LvaNq06lM5xjVccAtgYZnXRcBeG65kZoOBwQA77LBDhOWISGVss02YdLyshx4Kd8DOnAk//RSuuLnppnAiduHCEPTdukH37mF44k8+CVMZ/vwzdOoEBxwQhjb++uvw+Z9+CiHdv39Yv7g4LFu7NgT/zjuH54sXh+9Ysyb8R1FSEoI9Nzdsc9WqEOClQZ6TEx7LloWwX7u2/Bb9xtq3lVmejO9o0KD8dbdUlC3444FD3f3MxOtTgb3c/dyNfUYteBGRytlUCz7Kk6yLgO3LvG6ZWCYiItUgyoB/F2hrZq3NbCvgJOCZCLcnIiJlRNYH7+5rzexcYBKQA9zr7rOj2p6IiPxapMMFu/sLwAtRbkNERMqnO1lFRDKUAl5EJEMp4EVEMpQCXkQkQ0V2o1NVmFkxsKCKH28KZNs0A9rn7KB9znxbsr87unt+eW+kVMBvCTMr3NjdXJlK+5wdtM+ZL6r9VReNiEiGUsCLiGSoTAr40ZtfJeNon7OD9jnzRbK/GdMHLyIiv5ZJLXgRESlDAS8ikqHSPuAzdWJvM9vezKaa2cdmNtvMzk8sb2xmL5nZJ4mfjRLLzcxGJv4cPjCz38e7B1VnZjlm9p6ZPZd43drM3kns2yOJ4acxs1qJ158m3m8Va+FVZGYNzexxM5trZnPMrFumH2czuzDx9/ojMxtnZrUz7Tib2b1mttjMPiqzrNLH1cwGJNb/xMwGVKaGtA74DJ/Yey1wsbt3APYGzkns26XAFHdvC0xJvIbwZ9A28RgMjKr+kpPmfGBOmdc3Aje7+87A98AZieVnAN8nlt+cWC8d3QpMdPf2wO6Efc/Y42xmLYBhQIG7dyQMJ34SmXec7wcO3WBZpY6rmTUGriRMd9oVuLL0P4UKcfe0fQDdgEllXl8GXBZ3XRHt63+Ag4F5wLaJZdsC8xLP7wROLrP+L+ul04Mw89cU4EDgOcAId/jlbnjMCXMNdEs8z02sZ3HvQyX3twHw+YZ1Z/JxZv18zY0Tx+054JBMPM5AK+Cjqh5X4GTgzjLLf7Xe5h5p3YKn/Im9W8RUS2QSv5J2Ad4BtnH3rxJvfQ1sk3ieKX8WtwDDgZLE6ybAD+6+NvG67H79ss+J939MrJ9OWgPFwH2Jbqm7zawuGXyc3X0R8HfgC+ArwnGbQWYf51KVPa5bdLzTPeAznpnlAU8AF7j70rLvefgvPWOuczWzI4HF7j4j7lqqUS7we2CUu3cBVrD+13YgI49zI6AP4T+37YC6/LYrI+NVx3FN94DP6Im9zawmIdzHuvuTicXfmNm2ife3BRYnlmfCn0V34Ggzmw+MJ3TT3Ao0NLPS2cfK7tcv+5x4vwGwpDoLToIioMjd30m8fpwQ+Jl8nA8CPnf3YndfAzxJOPaZfJxLVfa4btHxTveAz9iJvc3MgHuAOe7+zzJvPQOUnkkfQOibL11+WuJs/N7Aj2V+FUwL7n6Zu7d091aEY/myu/cDpgLHJ1bbcJ9L/yyOT6yfVi1dd/8aWGhm7RKLegEfk8HHmdA1s7eZ1Un8PS/d54w9zmVU9rhOAnqbWaPEbz69E8sqJu6TEEk4iXE48F/gf8D/xV1PEvdrX8Kvbx8AsxKPwwl9j1OAT4DJQOPE+ka4ouh/wIeEKxRi348t2P8ewHOJ522A6cCnwGNArcTy2onXnybebxN33VXc185AYeJYPw00yvTjDPwVmAt8BDwE1Mq04wyMI5xjWEP4Te2MqhxX4PTEvn8KDKpMDRqqQEQkQ6V7F42IiGyEAl5EJEMp4EVEMpQCXkQkQyngRUQylAJeZAuYWY/SUS9FUo0CXkQkQyngJSuYWX8zm25ms8zszsSY88vN7ObEuORTzCw/sW5nM3s7MS73U2XG7N7ZzCab2ftmNtPMdkp8fZ6tH899bOLuTMzsBgvj+X9gZn+PadcliyngJeOZ2S7AiUB3d+8MrAP6EQa5KnT3XYFXCeNuAzwIXOLuuxHuKixdPhb4t7vvDuxDuEsRwkifFxDmJGgDdDezJsAxwK6J77kmyn0UKY8CXrJBL2AP4F0zm5V43YYwJPEjiXXGAPuaWQOgobu/mlj+ALC/mdUDWrj7UwDuvtLdf0qsM93di9y9hDCkRCvCkLYrgXvM7FigdF2RaqOAl2xgwAPu3jnxaOfuI8pZr6rjdqwq83wdYdKKtYQZeB4HjgQmVvG7RapMAS/ZYApwvJk1g1/mxdyR8Pe/dPTCU4DX3f1H4Hsz2y+x/FTgVXdfBhSZ2R8S31HLzOpsbIOJcfwbuPsLwIWEqfhEqlXu5lcRSW/u/rGZXQG8aGY1CKP7nUOYXKNr4r3FhH56CMO43pEI8M+AQYnlpwJ3mtlVie/ou4nN1gP+Y2a1Cb9BXJTk3RLZLI0mKVnLzJa7e17cdYhERV00IiIZSi14EZEMpRa8iEiGUsCLiGQoBbyISIZSwIuIZCgFvIhIhvr/3dHMJLFtN0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizzazione andamento addestramento\n",
    "\n",
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqPUlEQVR4nO3de3hU1b3/8feXBIKCcgl4AxXwjoCxRqzaKkpr8dJiK1QoWmw9x1vVU2x/ora1HI+2aC9aj1qrR6tVq1itFqsVRaxYrQIqVlFURNQgKAGMUOSS5Pv7Y+2BYZyEyezMTLL5vJ5nntmzZ83slc0wn1lr7b22uTsiIiKZOpS6AiIi0jYpIEREJCsFhIiIZKWAEBGRrBQQIiKSlQJCRESyUkCINMHM/mZm41u7bAvrMMzMalr7fUVyUV7qCoi0JjNbnfZwW2Ad0BA9PtPd78r1vdz92EKUFWkvFBCSKO7eNbVsZouA/3D36ZnlzKzc3euLWTeR9kZdTLJVSHXVmNlEM1sK/N7MepjZX81smZmtjJb7pr3m72b2H9HyaWb2DzP7ZVT2HTM7Ns+y/c1sppmtMrPpZna9md2Z49+xX7Stj81snpl9Le2548zsteh9F5vZD6P1vaK/7WMzW2FmT5uZ/u/LFulDIluTnYCewO7AGYTP/++jx7sBnwLXNfP6Q4A3gF7AVcAtZmZ5lP0jMAuoBCYBp+ZSeTPrCDwEPAbsAJwH3GVm+0RFbiF0o20HDAJmROt/ANQAvYEdgUsAzbEjW6SAkK1JI/BTd1/n7p+6+3J3v9/d17j7KuAK4MhmXv+uu9/s7g3A7cDOhC/cnMua2W7AwcCl7r7e3f8BTM2x/p8HugKTo9fOAP4KjI2e3wAMNLPt3X2lu7+Ytn5nYHd33+DuT7smYZMcKCBka7LM3demHpjZtmb2OzN718w+AWYC3c2srInXL00tuPuaaLFrC8vuAqxIWwfwfo713wV4390b09a9C/SJlk8CjgPeNbOnzOzQaP0vgAXAY2a20MwuynF7spVTQMjWJPNX8w+AfYBD3H174IhofVPdRq1hCdDTzLZNW7drjq/9ANg1Y/xgN2AxgLvPdveRhO6nB4F7o/Wr3P0H7j4A+BpwgZkNj/dnyNZAASFbs+0I4w4fm1lP4KeF3qC7vwvMASaZWafoV/5Xc3z588Aa4EIz62hmw6LX3hO91zgz6+buG4BPCF1qmNkJZrZnNAZSRzjstzHrFkTSKCBka3YNsA1QCzwHPFqk7Y4DDgWWA5cDUwjnazTL3dcTAuFYQp1vAL7t7vOjIqcCi6LusrOi7QDsBUwHVgP/BG5w9ydb7a+RxDKNVYmUlplNAea7e8FbMCItoRaESJGZ2cFmtoeZdTCzEcBIwpiBSJuiM6lFim8n4M+E8yBqgLPd/aXSVknks9TFJCIiWamLSUREskpMF1OvXr28X79+pa6GiEi78sILL9S6e+9szyUmIPr168ecOXNKXQ0RkXbFzN5t6jl1MYmISFYKCBERyUoBISIiWSVmDEJE2p4NGzZQU1PD2rVrt1xYCqpz58707duXjh075vwaBYSIFExNTQ3bbbcd/fr1o+lrK0mhuTvLly+npqaG/v375/w6dTGJSMGsXbuWyspKhUOJmRmVlZUtbskpIESkoBQObUM+/w4KiJgefxzefrvUtRARaX0KiJi+/W24+upS10JEMi1fvpyqqiqqqqrYaaed6NOnz8bH69evb/a1c+bM4fzzz9/iNg477LBWqevf//53TjjhhFZ5r9akQeqY1q0LNxFpWyorK5k7dy4AkyZNomvXrvzwhz/c+Hx9fT3l5dm/Aqurq6murt7iNp599tlWqWtbpRZETI2NsGFDqWshIrk47bTTOOusszjkkEO48MILmTVrFoceeigHHngghx12GG+88Qaw+S/6SZMm8d3vfpdhw4YxYMAArr322o3v17Vr143lhw0bxqhRo9h3330ZN24cqZmyH3nkEfbdd18OOuggzj///Ba1FO6++24GDx7MoEGDmDhxIgANDQ2cdtppDBo0iMGDB3N11IVx7bXXMnDgQIYMGcKYMWPi7ywK3IKILobyG6AM+D93n5zxfAXwB+AgwuUXT3b3RWnP7wa8Bkxy918Wsq75amyE+vpS10Kk7fv+9yH6Qd9qqqrgmmta9pqamhqeffZZysrK+OSTT3j66acpLy9n+vTpXHLJJdx///2fec38+fN58sknWbVqFfvssw9nn332Z84neOmll5g3bx677LILhx9+OM888wzV1dWceeaZzJw5k/79+zN27Nic6/nBBx8wceJEXnjhBXr06MExxxzDgw8+yK677srixYt59dVXAfj4448BmDx5Mu+88w4VFRUb18VVsBaEmZUB1xOunzsQGGtmAzOKnQ6sdPc9gauBKzOe/zXwt0LVsTU0NCggRNqT0aNHU1ZWBkBdXR2jR49m0KBBTJgwgXnz5mV9zfHHH09FRQW9evVihx124MMPP/xMmaFDh9K3b186dOhAVVUVixYtYv78+QwYMGDjuQctCYjZs2czbNgwevfuTXl5OePGjWPmzJkMGDCAhQsXct555/Hoo4+y/fbbAzBkyBDGjRvHnXfe2WTXWUsVsgUxFFjg7gsBzOwewqUVX0srMxKYFC3fB1xnZububmYnAu8A/y5gHWNTF5NIblr6S79QunTpsnH5Jz/5CUcddRQPPPAAixYtYtiwYVlfU1FRsXG5rKyM+iy/CnMp0xp69OjByy+/zLRp07jxxhu59957ufXWW3n44YeZOXMmDz30EFdccQWvvPJK7KAo5BhEH+D9tMc10bqsZdy9HqgDKs2sKzAR+O/mNmBmZ5jZHDObs2zZslareEuoBSHSftXV1dGnT/hauu2221r9/ffZZx8WLlzIokWLAJgyZUrOrx06dChPPfUUtbW1NDQ0cPfdd3PkkUdSW1tLY2MjJ510EpdffjkvvvgijY2NvP/++xx11FFceeWV1NXVsXr16tj1b6tHMU0Crnb31c2d3OHuNwE3AVRXV5fk2qkagxBpvy688ELGjx/P5ZdfzvHHH9/q77/NNttwww03MGLECLp06cLBBx/cZNknnniCvn37bnz8pz/9icmTJ3PUUUfh7hx//PGMHDmSl19+me985zs0NjYC8POf/5yGhgZOOeUU6urqcHfOP/98unfvHrv+BbsmtZkdShhc/kr0+GIAd/95WplpUZl/mlk5sBToDcwEdo2KdQcagUvd/bqmtlddXe2luGBQhw7wpS/BY48VfdMibd7rr7/OfvvtV+pqlNTq1avp2rUr7s73vvc99tprLyZMmFCSumT79zCzF9w96zG9heximg3sZWb9zawTMAaYmlFmKjA+Wh4FzPDgi+7ez937AdcAP2suHErFPdzUghCRptx8881UVVWx//77U1dXx5lnnlnqKuWsYF1M7l5vZucC0wiHud7q7vPM7DJgjrtPBW4B7jCzBcAKQoi0G1ELT4PUItKkCRMmlKzFEFdBxyDc/RHgkYx1l6YtrwVGb+E9JhWkcq2goSHcqwUh0jR314R9bUA+wwk6kzqGVAtCASGSXefOnVm+fHleX07SelLXg+jcuXOLXtdWj2JqF9TFJNK8vn37UlNTQ6kOQ5dNUleUawkFRAzqYhJpXseOHVt0BTNpW9TFFIO6mEQkyRQQMaRaEOpiEpEkUkDEoBaEiCSZAiIGBYSIJJkCIgZ1MYlIkikgYlALQkSSTAERg86DEJEkU0DEoPMgRCTJFBAxqItJRJJMARFDegtCU82ISNIoIGJItSBgU1iIiCSFAiKG9IBQN5OIJI0CIob0VoOOZBKRpFFAxKAWhIgkmQIiBrUgRCTJFBAxqAUhIkmmgIhBASEiSaaAiEFdTCKSZAqIGNSCEJEkU0DEkN6CUECISNIoIGJIb0Goi0lEkkYBEYO6mEQkyRQQMaiLSUSSTAERg7qYRCTJFBAxqItJRJJMARGDzoMQkSRTQMSgFoSIJJkCIgYNUotIkikgYtAgtYgkmQIiBnUxiUiSKSBiUBeTiCSZAiIGdTGJSJIpIGJQC0JEkkwBEYNaECKSZAqIGDRILSJJpoCIQV1MIpJkBQ0IMxthZm+Y2QIzuyjL8xVmNiV6/nkz6xetH2pmc6Pby2b29ULWM1/qYhKRJCtYQJhZGXA9cCwwEBhrZgMzip0OrHT3PYGrgSuj9a8C1e5eBYwAfmdm5YWqa77UghCRJCtkC2IosMDdF7r7euAeYGRGmZHA7dHyfcBwMzN3X+Puqa/czoAXsJ550xiEiCRZIQOiD/B+2uOaaF3WMlEg1AGVAGZ2iJnNA14BzkoLjI3M7Awzm2Nmc5YtW1aAP6F56mISkSRrs4PU7v68u+8PHAxcbGads5S5yd2r3b26d+/eRa+juphEJMkKGRCLgV3THveN1mUtE40xdAOWpxdw99eB1cCggtU0T+piEpEkK2RAzAb2MrP+ZtYJGANMzSgzFRgfLY8CZri7R68pBzCz3YF9gUUFrGteUgFhpi4mEUmegh0Z5O71ZnYuMA0oA25193lmdhkwx92nArcAd5jZAmAFIUQAvgBcZGYbgEbgHHevLVRd85XqYqqoUAtCRJKnoIeOuvsjwCMZ6y5NW14LjM7yujuAOwpZt9aQakFUVKgFISLJ02YHqduDVAuiUye1IEQkeRQQMaS3IBQQIpI0CogY1MUkIkmmgIhBXUwikmQKiBgaG6FDBygvV0CISPIoIGJoaAgB0bGjuphEJHkUEDE0NkJZmVoQIpJMCogYUl1MHTsqIEQkeRQQMTQ0bGpBqItJRJJGARGDBqlFJMkUEDFokFpEkkwBEYMGqUUkyRQQMaiLSUSSTAERQ2qQWl1MIpJECogY1IIQkSRTQMSggBCRJFNAxKAuJhFJMgVEDGpBiEiSKSBi0JnUIpJkCogYNBeTiCSZAiIGdTGJSJIpIGJQF5OIJJkCIgZ1MYlIkikgYkhvQTQ2hpuISFIoIGJIH4MAtSJEJFkUEDGkdzGBAkJEkkUBEUN6FxMoIEQkWRQQMWR2MelIJhFJEgVEDOlzMYFaECKSLAqIGNSCEJEkU0DEkAqITp3C4/XrS1sfEZHWpICIIdXFVFERHq9bV9r6iIi0JgVEDKkWROfO4bECQkSSJKeAMLP/MrPtLbjFzF40s2MKXbm2LhUQqRbE2rWlrY+ISGvKtQXxXXf/BDgG6AGcCkwuWK3aCXUxiUiS5RoQFt0fB9zh7vPS1m21MruY1IIQkSTJNSBeMLPHCAExzcy2A7b6qenUghCRJCvPsdzpQBWw0N3XmFlP4DsFq1U7oUFqEUmyXFsQhwJvuPvHZnYK8GOgrnDVah80SC0iSZZrQPwWWGNmBwA/AN4G/rClF5nZCDN7w8wWmNlFWZ6vMLMp0fPPm1m/aP2XzewFM3sluj869z+peNTFJCJJlmtA1Lu7AyOB69z9emC75l5gZmXA9cCxwEBgrJkNzCh2OrDS3fcErgaujNbXAl9198HAeOCOHOtZVOpiEpEkyzUgVpnZxYTDWx82sw5Axy28ZiiwwN0Xuvt64B5CwKQbCdweLd8HDDczc/eX3P2DaP08YBszq8ixrkWT2YJQF5OIJEmuAXEysI5wPsRSoC/wiy28pg/wftrjmmhd1jLuXk8Y16jMKHMS8KK7f+b3uZmdYWZzzGzOsmXLcvxTWk/mGIRaECKSJDkFRBQKdwHdzOwEYK27b3EMIi4z25/Q7XRmE/W6yd2r3b26d+/eha7OZ2RO1qcWhIgkSa5TbXwTmAWMBr4JPG9mo7bwssXArmmP+0brspYxs3KgG7A8etwXeAD4tru/nUs9iy3VxWQWWhFqQYhIkuR6HsSPgIPd/SMAM+sNTCeMGzRlNrCXmfUnBMEY4FsZZaYSBqH/CYwCZri7m1l34GHgInd/Jsc6Fl2qBQFhoFoBISJJkusYRIdUOESWb+m10ZjCucA04HXgXnefZ2aXmdnXomK3AJVmtgC4AEgdCnsusCdwqZnNjW475FjXokm1ICC0INTFJCJJkmsL4lEzmwbcHT0+GXhkSy9y90cyy7n7pWnLawndVpmvuxy4PMe6lUx6C0JdTCKSNDkFhLv/PzM7CTg8WnWTuz9QuGq1D+piEpEky7UFgbvfD9xfwLq0O+piEpEkazYgzGwV4NmeAtzdty9IrdoJtSBEJMmaDQh3b3Y6ja1dY6NaECKSXLomdQwNDRqkFpHkUkDEoC4mEUkyBUQMGqQWkSRTQMSgFoSIJJkCIk/u4ZbeglBAiEiSKCDy1NgY7tMHqdXFJCJJooDIU2ZAqItJRJJGAZGnhoZwr0FqEUkqBUSemmpBeLbzzkVE2iEFRJ5SAZHeggDYsKE09RERaW0KiDylupjSB6lB3UwikhwKiDxl62ICDVSLSHIoIPKUbZAa1IIQkeRQQOQp23kQoBaEiCSHAiJPmYPU6mISkaRRQORJg9QiknQKiDxpkFpEkk4BkaemzoNQQIhIUigg8qQuJhFJOgVEnjRILSJJp4DIk1oQIpJ0Cog8aZBaRJJOAZEnDVKLSNIpIPLUlruYNOW4iLQGBUSe2moX0/33Q2UlzJ1b2nqISPungMhTU5P1lTIgHnoITj4ZVq6Et94qXT1EJBkUEHnKbEGUl4ewKGUX0zXXwPbbh+VVq0pXDxFJBgVEnjIHqSG0IkrZglizBgYMCMsKCBGJSwGRp8xBaggBUcoWxLp1YfwBYPXq0tVDRJJBAZGnzC4mCAPVpWxBrF0bupg6dVILQkTiU0DkKXOQGkrfgli7NoTUdtspIEQkPgVEnrK1IEr9xZwKiK5d1cUkIvEpIPKUbZC6Z09YsaI09YHQvaUWhIi0FgVEnrINUldWwvLlpakPhBZERYUCQkRahwIiT9m6mErZgnDfvItJASEicRU0IMxshJm9YWYLzOyiLM9XmNmU6PnnzaxftL7SzJ40s9Vmdl0h65ivbF1MqRZEKeZCqq8PdUp1MWkMQkTiKlhAmFkZcD1wLDAQGGtmAzOKnQ6sdPc9gauBK6P1a4GfAD8sVP3iytbF1LMnrF8fTlgrttTRUxqDEJHWUsgWxFBggbsvdPf1wD3AyIwyI4Hbo+X7gOFmZu7+b3f/ByEo2qSmWhBQmnGI1PkXCggRaS2FDIg+wPtpj2uidVnLuHs9UAdU5roBMzvDzOaY2Zxly5bFrG7LNNWCgNKMQ6RaEBUVOsxVRFpHux6kdveb3L3a3at79+5d1G1nG6QuZQsis4tpw4bSTz0uIu1bIQNiMbBr2uO+0bqsZcysHOgGlPBA0dw1dR4ElLYFkQoIUDeTiMRTyICYDexlZv3NrBMwBpiaUWYqMD5aHgXMcG8f10Nr6jwIKH0LomvXsKxuJhGJo7xQb+zu9WZ2LjANKANudfd5ZnYZMMfdpwK3AHeY2QJgBSFEADCzRcD2QCczOxE4xt1fK1R9W6q5FkRbGKQGtSBEJJ6CBQSAuz8CPJKx7tK05bXA6CZe26+QdYurqem+u3Qp/SC1AkJEWkNBAyLJsg1SQ2hFlLqLKdWqUUCISBwKiDxl62KCMA5R6kHqzp3DssYgRCQOBUSesnUxQelaEOljEB07hmW1IEQkjnZ9HkQptdUWhMYgRKS1KCDy1FQLolRTfuswVxFpbQqIPDU3SL1iRfFndE0PiIoKKC9XC0JE4lFA5Km5LqaGBvjkk+LWJz0gzDRhn4jEp4DIU3OD1FD8cYjUIHWnTuG+LU7YN3EizJxZ6lqISK4UEHlKffluu+3m6/tE89W+805x65O63KhZeNzWWhDr1sFVV8G995a6JiKSKwVEnpYvh+233/SLPWXIkHD/8svFrU/qcqMpbS0gPvpo83sRafsUEHmqrd00OV+6HXeEnXeGuXOLW5/MgGhrXUxLl4Z7BYRI+6GAyNPy5dkDAqCqqvgBsW7d5gHRrRusXFncOjQnFRAffljaeohI7hQQedpSQLz2WnEv2JPZghgwABYu3HS0VamlgkEtCJH2QwGRp9pa6NUr+3NVVVBfH0KiWFKD1Cl77x0C6r33ileH5qRaECtWhKvdiUjbp4DIU3MtiAMPDPfF7GbKbEHsvXe4f/PN4tWhOamAACjy5cNFJE8KiDxs2BBOhGsqIPbYI1wXopQBsc8+4b4tBoS6mUTaBwVEHlJzLTXVxdShAxx8MEyfXrwpNzIHqXfcMRzq+sYbxdn+lnz44ab6KSBE2gcFRB5SAdFUCwLg5JPDGESxWhGZLQiz0IpoSy2IQYPCso5kEmkfFBB5yCUgvvnNcBLdHXcUp06Zg9QQxiHaSgti6VIYPDgsqwUh0j4oIPJQWxvum+pigjAn0/HHwx//GI5oKrTMFgSEgHjvPfj008Jvvzn//nc4aW/vvUNoKiBE2gcFRB5yaUEAjB8fulN+//vC1ylzDAJCF5M7vP124bffnFSX0s47ww47qItJpL1QQNDygeRcA+KrX4Vhw+AHPyj8+QhNtSAA5s0r7La3JHUE0047hcFztSBE2oetPiCWLIFDDoFnn839NbW1sM02n53JNVOHDnDrreFs5lNO2XTNhkLINgYxeHDo6nroocJtNxfpAbHDDgoIkfZiqw+I2trQIjjiCPjpT3Prr2/uJLlM/fvDzTfDP/4RjmwqxFnE7tlbEB07woknwtSpxZ32I1NmQKiLSaR92OoDYvBgeOklGDMGLrsM9tsP7ruv+W6nlgQEwNixcN114Yt65MjWn2V1w4ZQ38yAABg9Okz7/fjjrbvNlliyJLSmevXa1IIo9iVZRaTltvqAgHBdhzvvhBkzwvLo0XD00U1f06G5eZiacs45cNNN8NhjcPjhrTsukGodZAuIo4+G7t3hT39qve211KJFsOuu4fKsO+8M69erm0mkPVBApDnqKHjxRfjtb+GVV+Bzn4NTT/3sl3lLWxAp//mf8PDD4Rd1dTX87/+2zi/p9OtRZ+rUCUaNCldyK9U5EYsWQb9+YfnQQ8P9U0+Vpi4ikjsFRIbycjjrLHjrLbjgAvjzn8MZwAcdBL/7HcyfH/rU8wkIgK98JYTP8OFw/vkwYgTU1MSrcyogMgepUy67LAyqn3bapmtpF1N6QFRXh1baE08Uvx4i0jIKiCb06AG/+EX4crv66vBL/6yzwhjFJ5/A0KH5v/eOO4Yji264IQxeDxoEkyblHxTNtSAgdOtcfz089xz8+Mf5bSNf69fD4sWbAqK8HI48UgEh0h4oILagd2/4/vfhhRfgySfh2mvh3XfDr/E4zODss+Ff/4IvfjH8yt999zCI/cADLTsktrkxiJQxY+CMM2DyZLjqquKNAbz/fgjXVEBAaD29/XbYjyLSdikgcmQWTno77zzYbbfWe9899gitibffhokTw6/8b3wjtDJOOw3+9rfwK7w5W2pBQKj/9dfDsceG7ey4I5x7buGnAVm0KNxnBgSoFSHS1ikg2oj+/eFnPwvdMdOmhZB44AE47rhwaOj48eHw2xUrPvvaXAICQvfO1KlhgPicc0JgnHBCYX/Jv/NOuE8PiP33hz59whQkOtxVpO1SQLQx5eVwzDHhy/Ojj+Cvf4Wvfz18sY8eHQ6vHTo0dE9ddVU4A/y3vw2v7dYtt/c/4ogQDjfeCDNnwr77htbEiy+2/hf2okXh8Na+fTetM4Of/CSMv/zlL627PRFpPeYJ+QlXXV3tc+bMKXU1CmbDBpg1K5zwNn16OJoqNSeUGVx8MVx+eVhuiffeC1/WU6aEsYwhQ8I4yCGHhFtLz/fIdMop8Mwzm1oSKfX1YVv19SHk4m4njv/5n3B2969/HQ4LFtmamNkL7l6d9TkFRPu1bFkYOB8wIBw+GsfHH8M998Btt8Hs2WH+KAhjJEOHQlVVOOt8yBDYZZfcg+gLXwhTfjz55Gefmz49TIleWQm/+hWcdFLxv6CfeSbUEeDLX4YHH9zyHFsiSaKAkBZZvToctfX882HQfPbszQ/B7dkzhMXgwTBwYOii2mef0ArI/ILv2zd88TY15fncuaGVMW9eGGs55pgwiH300eHs65a2iFpiw4ZwMmRdHVx0UehmO+ecMC1KMTQ2hgtKvflmGJf51reKs12RdM0FRHmxKyNtX9eu4VyFI4/ctG7lynCC37/+ten+tts+O69U585hLGSPPcJ4xuLFoYXTlKqqMKXJtGnhy3LatDDtCYTAGTIEDjgg3O+/P+y1V5g6pDX86Efw6qvhYIATTwwnR15zTThA4OijW2cbzfnZz0L3nlnYVx06hMORRdoKtSAkb6kAmD8//ApeuTL8Gl+5Mjxety6cKX7eebmfed7YGL60Z84MwfHyy+Fx+iy7lZXhqKiddw4zxKbu02+9esF2223eAkl91Nevh9tvhzPPDIP9N9wQ1q9ZEwJr8eJQ5wkTwuHAhTBjRmhZjR0bpoQfPjwcJDBjRhj7KbWGhtDl+NRT8MtfhrPfJZnUxSTtWkMDLFgQguitt8Lyu++GKU+WLg1He6XGTNKVlYXWRu/eoWWzYEEIrQ4dwv2hh4axkfQpShYtgksuCV+O5eVhapT99oM99wyhVFm56da1a35dYEuWwIEHhq66WbPC+yxdGuqzZEkYLB8/Hrp0yXOHxfTpp+Gcn1mzwuORI8OUMx10zGMilSwgzGwE8BugDPg/d5+c8XwF8AfgIGA5cLK7L4qeuxg4HWgAznf3ac1tSwGx9WpoCAP2qcBYsiScL7JiRWjN1NaG62LvsUcYgK6vD11Iw4c3PX/Vm2+GQ4GnTw8nMWa7nkbHjuFLvkeP0Frp2nXLN7Mwq++LL4axnYEDN71fbW24ZsiMGaGeBxwQQql79/ALvlu3cJ+6bbNNCL5ttsm+3Llzfl/qZ54Z6njbbWH/TZgQur4uuCC0sDp2bPl7SttVkoAwszLgTeDLQA0wGxjr7q+llTkHGOLuZ5nZGODr7n6ymQ0E7gaGArsA04G93b3JqeYUEFIoDQ2h2+m998KhxStWhPvU8ooVIYBWr978tmpVWJ/5X6ysLHRxjRv32W01NobutT//OYz1vPdemPurri6/i01VVGwKjk6dwpd7U/cdO4a/adascLb95Mmh7pdcAr/5TWhZlJeHgwnSQ69Ll83fo7lbruXKyja/deiQ+7o1a8I+W7kS/vnPEPDV1ZsOpOjdOwRw6vXN3Zs1fUuKUgXEocAkd/9K9PhiAHf/eVqZaVGZf5pZObAU6A1clF42vVxT21NASFvU2Bi+WFOBAaF7qkePlr/XunWbwmLVqvC+n34azqRPLTf3eP36EDKZ9+nL3buH7q8rrti8pbByZZiq/vXXQ5deZhimv1dzt2L3aJeXh7P2CzFbQFPB0VSwNBc4cZ877rhwqHh+f0dpjmLqA7yf9rgGyBx+21jG3evNrA6ojNY/l/HaPpkbMLMzgDMAdmvNCZJEWkmHDuEXdpcu8Qe8KyrCr9/evVunbi3Ro0c4HDmuhobcgqSh4bO3xsbs6zOf23bbTV1y++4bWjm1taE1VlsbuiPXrt38dU3duzd9a2xs+XP5vCaX53bdNf6/TTbt+jBXd78JuAlCC6LE1RGRLUh1BW1p3rDW1qtXac/Wb68KeVzCYiA91/pG67KWibqYuhEGq3N5rYiIFFAhA2I2sJeZ9TezTsAYYGpGmanA+Gh5FDDDw6DIVGCMmVWYWX9gL2BWAesqIiIZCtbFFI0pnAtMIxzmequ7zzOzy4A57j4VuAW4w8wWACsIIUJU7l7gNaAe+F5zRzCJiEjr04lyIiJbseaOYtK5kSIikpUCQkREslJAiIhIVgoIERHJKjGD1Ga2DIhzQn0voLaVqtOaVK+WUb1arq3WTfVqmXzrtbu7Zz0/PzEBEZeZzWlqJL+UVK+WUb1arq3WTfVqmULUS11MIiKSlQJCRESyUkBsclOpK9AE1atlVK+Wa6t1U71aptXrpTEIERHJSi0IERHJSgEhIiJZbTUBYWYTzGyemb1qZnebWedoKvLnzWyBmU2JpiUnmmZ8SrT+eTPrV+R63WVmb0TrbjWzjlHZYWZWZ2Zzo9ulRa7XbWb2Ttr2q6KyZmbXRvvrX2b2uSLX6+m0On1gZg9GZYu2v6Lt/VdUr3lm9v1oXU8ze9zM3orue0Tri7nPstXrF2Y2P9r2A2bWPVrfz8w+TdtnNxa5XpPMbHHa9o9LK39xtL/eMLOvFLleU9LqtMjM5kbrC7q/ov//H5nZq2nrWvyZMrPxUfm3zGx8tm1l5e6JvxEuV/oOsE30+F7gtOh+TLTuRuDsaPkc4MZoeQwwpcj1Og6w6HZ3Wr2GAX8t4f66DRiVpfxxwN+i+n4eeL6Y9coocz/w7WLur2hbg4BXgW0J0+hPB/YErgIuispcBFxZ5H3WVL2OAcqjMlem1asf8GoJ99ck4IdZyg8EXgYqgP7A20BZseqVUeZXwKXF2F/AEcDn0rfR0s8U0BNYGN33iJZ75LL9raYFQfjH3sbCleu2BZYARwP3Rc/fDpwYLY+MHhM9P9zMrEj1+sDdH/EI4UJJfQu07RbVq5myI4E/RFV+DuhuZjsXu15mtj3h3/TBAm27OfsR/kOucfd64CngG2z+Wcr8jBVjn2Wtl7s/Fj2GcP33Yn/GmtpfTRkJ3OPu69z9HWABMLTY9Yq+B75J+OFWcO4+k3CtnHQt/Ux9BXjc3Ve4+0rgcWBELtvfKgLC3RcDvwTeIwRDHfAC8HHaf5Iawi9Uovv3o9fWR+Uri1Evd38s9byFrqVTgUfTXnaomb1sZn8zs/1bu0451OuKqPl6tZlVROs27q9I+r4sVr0g/Ed5wt0/SVtX8P0VeRX4oplVmtm2hF9zuwI7uvuSqMxSYMdouSj7rJl6pfsu4ZdnSn8ze8nMnjKzLxagTluq17nRZ+zWVPcJbWd/fRH40N3fSltXjP2VrqWfqbz33VYRENGHbCShaboL0IUcE7SQstXLzE5JK3IDMNPdn44ev0iYN+UA4H8p0C/lZup1MbAvcDChuTqxENvPo14pY9n8l11R9heAu79O6Kp5jBDoc4GGjDIOFPW48i3Vy8x+RLhq413RqiXAbu5+IHAB8MeoZVasev0W2AOoiuryq9bedp71Ssn8jBVlfzWl0J+prSIggC8B77j7MnffAPwZOJzQBEtddrUvsDhaXkz0qyF6vhuwvEj1Oiza7k+B3oQPHQDu/om7r46WHwE6mlmvYtXL3ZdEzdd1wO/Z1MTfuL8i6fuy4PUCiPbDUODhVOEi7q/U9m5x94Pc/QhgJfAm8GGq6yi6/ygqXqx91lS9MLPTgBOAcdEXDVEXzvJo+QVCX//exaqXu3/o7g3u3gjcTPE/Y83tr3JCd9OUtLJF219pWvqZynvfbS0B8R7weTPbNupDHE643vWTwKiozHjgL9Hy1Ogx0fMzUv+BilCv183sPwj9hmOj/ygAmNlOqbEQMxtK+PcrRHA1Va/Uh9II3TmpIyumAt+OjqL4PKHrZ0mW9y1IvaLnRhEGpNemChdxf6W2t0N0vxvhi+SPbP5ZyvyMFWOfZa2XmY0ALgS+5u5r0sr2NrOyaHkAsBdhULNY9Uofh/k6m3/Gxlg4wrB/VK9ZxapX9NSXgPnuXpNWtmj7K01LP1PTgGPMrEfUCj8mWrdlzY1gJ+kG/Dcwn/CBu4NwNMQAwodsAfAnoCIq2zl6vCB6fkCR61VP+CUyN7qljpg4F5hHOJrjOcKv+mLWawbwSrTuTqBrVNaA66M6vwJUF7Ne0fq/AyMyyhZtf0Xbe5rww+NlYHi0rhJ4AniLcERMzxLss2z1WkDol059xlJH7Z0U7bO5hC66rxa5XndE++NfhC+8ndPK/yjaX28AxxazXtH624CzMsoWdH8RurOWABsIYwen5/OZIowzLYhu38l1+5pqQ0REstpauphERKSFFBAiIpKVAkJERLJSQIiISFYKCBERyUoBIVIiFmab/Wup6yHSFAWEiIhkpYAQ2QIzO8XMZlmY7/93ZlZmZqujCQvnmdkTZtY7KltlZs/ZpusspObq39PMpkcTB75oZntEb9/VzO6zcG2Gu9LO/J5sZq9F7/PLEv3pspVTQIg0w8z2A04GDnf3KsLEbeMIEz7Ocff9CVNC/zR6yR+Aie4+hHA2a2r9XcD1HiYOPIxwdizAgcD3Cdc7GAAcbmaVhGkm9o/e5/JC/o0iTVFAiDRvOHAQMNvCVcSGE77IG9k0adudwBfMrBvQ3d2fitbfDhxhZtsBfdz9AQB3X+ub5j+a5e41Hubcmku4AE0dsBa4xcy+AWycK0mkmBQQIs0z4HZ3r4pu+7j7pCzl8p2zZl3acgPhKm/1hFlM7yPMtvpotheKFJoCQqR5TwCj0mb47GlmuxP+76RmAv4W8A93rwNWpl005lTgKXdfBdSY2YnRe1RYuBhNVmbWFejmYYryCcABBfi7RLaofMtFRLZe7v6amf0YeMzMOhBm1fwe8G9gaPTcR4RxCgjTL98YBcBC4DvR+lOB35nZZdF7jG5ms9sBfzGzzoQWzAXNlBUpGM3mKpIHM1vt7l1LXQ+RQlIXk4iIZKUWhIiIZKUWhIiIZKWAEBGRrBQQIiKSlQJCRESyUkCIiEhW/x+br6GKOe38QwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizzazione andamento della\n",
    "# parte finale dell'addestramento\n",
    "\n",
    "plt.plot(epochs[800:], acc[800:], 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs[800:], loss[800:], 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase iniziale: ['TEMPO', 'SI', 'ACCOSTÒ', 'ALLA', 'NAVE', 'LA', 'TOCCÒ', 'E', 'SUBITO', 'SI', 'APRÌ', 'UN', 'PORTELLO', 'FORD', 'E', 'ZAPHOD', 'LO', 'FISSARONO', 'SBALORDITI', 'DI', 'NIENTE', 'DISSE', 'MARVIN', 'AH', 'GIÀ', 'VI', 'FACCIO', 'NOTARE', 'CHE', 'NON', 'MI', 'AVETE', 'NEANCHE', 'DETTO', 'GRAZIE', 'SI', 'ALLONTANÒ', 'DI', 'NUOVO', 'STRASCICANDO', 'I', 'PIEDI', 'ARTHUR', 'E', 'TRILLIAN', 'SI', 'AVVICINARONO', 'ALL', 'ASTRONAVE', '', 'COSA', 'STA', 'SUCCEDENDO', '', 'DISSE', 'ARTHUR', '', 'GUARDA', 'QUA', '', 'DISSE', 'FORD', '', 'GUARDA']\n",
      "solo secondo lo da nel davanti il ___ la simile un girò sopra lo ford casualità tanto forte e me quando arthur tanto poco ford lì all ostilità in siano ___ per effetti i che orbita o così fare avrebbero sai qui che macchina pareva male dal brillava dall immensità aperto ogni tranne ___ e portarci confini più stare distanza pensò secondo mani la immensità direzione mezzo tal siepe ___ se è stare direzione cose è due improbabilità vita thrashbarg immensità volta ___ ___ ci aria più mezzo più quel stare mai assoluto totale un serie di era luce erano "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = get_model()\n",
    "model.load_weights('weights/words_generation')\n",
    "\n",
    "# generazione nuovo testo\n",
    "\n",
    "seed_text = texts[42000][:-1]\n",
    "print('Frase iniziale:', seed_text)\n",
    "\n",
    "next_words = 100\n",
    "\n",
    "reverse_word_map = (dict(map(reversed, tokenizer.word_index.items())))\n",
    "\n",
    "for i in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences(seed_text)\n",
    "    for i, t in enumerate(token_list):\n",
    "        if len(token_list[i]) == 0:\n",
    "            token_list[i] = [1]\n",
    "    token_list = np.asarray(token_list)\n",
    "    token_list = np.reshape(np.asarray(np.squeeze(token_list)), (1, len(examples[0]), 1))\n",
    "    pred_token = model.predict(token_list, verbose=0)\n",
    "    pred_token = (pred_token[0]).argsort(axis=-1)[-5:]\n",
    "    # variazione casuale della selezione del migliore output\n",
    "    # permette di avere un output più \"creativo\" e meno\n",
    "    # simile al testo di addestramento\n",
    "    rnd = np.random.random()\n",
    "    if rnd > 0.975:\n",
    "        pred_token = pred_token[4]\n",
    "    elif rnd > 0.95:\n",
    "        pred_token = pred_token[3]\n",
    "    elif rnd > 0.90:\n",
    "        pred_token = pred_token[2]\n",
    "    elif rnd > 0.85:\n",
    "        pred_token = pred_token[1]\n",
    "    else:\n",
    "        pred_token = pred_token[0]\n",
    "    word_predicted = tokenizer.sequences_to_texts([[pred_token]])[0]\n",
    "    print(word_predicted + ' ', end='')\n",
    "    seed_text = np.append(seed_text, pred_token)\n",
    "    seed_text = seed_text[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}